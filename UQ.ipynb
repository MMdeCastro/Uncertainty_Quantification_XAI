{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6113ef90",
   "metadata": {},
   "source": [
    "![banner](./images/banner.png \"banner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e88f89",
   "metadata": {},
   "source": [
    "[Fuente de la imagen](https://unsplash.com/photos/Hcfwew744z4)\n",
    "<a name='toc' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5a1bb",
   "metadata": {},
   "source": [
    "# <font color=#ac6240>Cuantificación de la incertidumbre en la predicción de fallo cardíaco con aprendizaje automático supervisado</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c022a3",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>Tabla de Contenidos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5121342",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "<a href=#pre>Requisitos previos</a><br>\n",
    "1. <a href=#project-description>Descripción del proyecto</a><br>\n",
    "    1.1 <a href=#project-description-intro>Introducción</a><br>\n",
    "    1.2 <a href=#project-description-goal>Objetivo</a><br>\n",
    "    1.3 <a href=#project-description-data>Datos y modelo de aprendizaje automático</a><br>\n",
    "    1.4 <a href=#project-description-software>Software</a><br>\n",
    "2. <a href=#prep>Preparación de los datos</a><br>\n",
    "    2.1 <a href=#prep-clean> Limpieza de los datos</a><br>\n",
    "    2.2 <a href=#prep-split> Division de los datos en conjuntos de datos de entrenamiento, validación y prueba</a><br>\n",
    "    2.3 <a href=#prep-encoding> Codificación y normalización de las 'features'</a><br>\n",
    "3. <a href=#model-ml>Aplicación del modelo de aprendizaje automático: Bosque Aleatorio</a><br>\n",
    "    3.1 <a href=#model-metric> Selección de la métrica y del umbral de decisión </a><br>\n",
    "    3.2 <a href=#model-RF> Entrenamiento, prueba, y aplicación del bosque aleatorio </a><br>\n",
    "4. <a href=#app-uq>Cuantificación de incertidumbre</a><br>\n",
    "    4.1 <a href=#uq-cp> Conformal Predictors </a><br>\n",
    "    4.2 <a href=#uq-others> Otros métodos de UQ para aprendizaje supervisado </a><br>\n",
    "    4.3 <a href=#miscelanea> Miscelánea </a><br>\n",
    "    \n",
    "5. <a href=#uq-end>Conclusión sobre la cuantificación de incertidumbre</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa782be",
   "metadata": {},
   "source": [
    "Antes de nada, me gustaría agradecer a les expertes [Maria Navarro](https://www.linkedin.com/in/maria-navarro-jimenez/) y a [Valeriy Manokhin](https://www.linkedin.com/in/valeriy-manokhin-phd-mba-cqf-704731236/) su inestimable ayuda en la elaboracion de este Jupyer Notebook. Podéis encontrar las referencias a sus trabajos acreditadas a lo largo de este taller.\n",
    "\n",
    "<font size=\"5\">😊 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487389a0",
   "metadata": {},
   "source": [
    "<a name='pre'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b570187",
   "metadata": {},
   "source": [
    "## <font color=#ac6240>Requisitos previos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2765775",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Este Jupyter Notebook puede recorrerse de manera independiente aunque es la continuación de los Jupyter Notebooks de [este repositorio](https://github.com/MMdeCastro/Uncertainty_Quantification_XAI):\n",
    "+ `Exploration_and_Classification.ipynb` donde explicamos cómo explorar exhaustivamente los datos de pacientes que sufrieron o no fallo cardíaco y cómo evaluar la calidad de un modelo de aprendizaje automático supervisado con métricas de rendimiento; elegimos el modelo que mejor se comportaba para este proyecto de predicción de fallo cardíaco y era un bosque aleatorio, y\n",
    "+ `XAI.ipynb` donde aplicamos varios métodos de explicabilidad sobre las predicciones de ese bosque aleatorio para entender en qué se fijó el modelo para clasificar a les pacientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be3f2b8",
   "metadata": {},
   "source": [
    "<font size=\"5\"> 👍🤓</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6814bca",
   "metadata": {},
   "source": [
    "<a name='project-description'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5b1b4",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "##  <font color=#ac6240>1. Descripción del proyecto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0f062",
   "metadata": {},
   "source": [
    "<a name='project-description-intro'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feaa428",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>1.1 Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cecda5",
   "metadata": {},
   "source": [
    "Estamos acostumbrades a modelos de aprendizaje automático que nos devuelven una predicción en forma de un único valor puntual ('single-value prediction'). Estos modelos no tienen ninguna manera de manifestar si están muy seguros o no de lo que predicen, por ejemplo, proporcionando una distribución o rango de resultados razonables, para que podamos representar la predicción con unas 'barras de error' en lugar de con un solo punto. \n",
    "\n",
    "La falta de información sobre la certeza que tiene un modelo sobre los resultados que arroja es especialmente problemático cuando:\n",
    "+ el modelo no es interpretable, es una 'black box' o caja opaca, (explicamos estos conceptos en el Jupyter Notebook anterior `XAI.ipynb`), o\n",
    "+ pedimos al modelo que prediga un resultado sobre una instancia anómala ('outlier') que no se parece a los datos históricos con los que ese modelo fue entrenado, algo relacionado con el fenómeno denominado ['drift'](https://en.wikipedia.org/wiki/Drift_(data_science)) (más info sobre la definición de 'deriva' o desplazamiento 'shift' y sus diferentes tipos, [aquí](https://analyticsindiamag.com/concept-drift-vs-data-drift-in-machine-learning/)), lo cual es indeseado y puede pasar fácilmente desapercibido. \n",
    "\n",
    "Por último remarcar que medir la certeza de las predicciones es especialmente útil en aplicaciones sensibles o de riesgo donde desarrollar algoritmos robustos y confiables es esencial. Según el acta reguladora de la inteligencia artificial de la Unión Europea, [The AI Act](https://artificialintelligenceact.eu/the-act/):\n",
    "\n",
    "    \"The purpose of this Regulation is to improve the functioning of the internal market and promoting the uptake of human centric and trustworthy artificial intelligence\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b1254",
   "metadata": {},
   "source": [
    "Como ejemplo sencillo, supongamos que entrenamos una red neuronal artificial (que no es interpretable) con imágenes de perres y gates con la tarea de distinguir entre perres y gates. Digamos que el umbral de decisión es tal que las instancias, es decir, las fotos, cuya 'raw score' sea mayor de 0.5 serán clasificadas como gates y el resto como perres, como en una típica clasificación binaria. Supongamos además que conseguimos que la red neuronal artificial tenga un rendimiento excelente sobre los datos de validación y testado, puede que incluso tenga un 99.5% en 'accuracy' sobre ambos conjuntos. Ahora, aplicamos la red y le pedimos que clasifique estas fotos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b77bf",
   "metadata": {},
   "source": [
    "![cat_dog_bird](./images/cat_dog_bird.png \"cat_dog_bird\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7649a",
   "metadata": {},
   "source": [
    "[Fuente de la imagen: _\"Are you sure about that?! Uncertainty Quantification in AI\"_](https://florianwilhelm.info/2019/10/uncertainty_quantification_in_ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c7b4de",
   "metadata": {},
   "source": [
    "Y vemos que ocurre lo siguiente:\n",
    "+ para la foto de la izquierda nos da una 'raw score' de 0.9, así que predice correctamente que es la imagen de une gate,\n",
    "+ para la foto del centro obtenemos una 'raw score' de 0.5, y a la vista de la imagen _interpretamos_ que a la red le costó darnos una clasificación correcta (nos la dió por los pelos) y que _obviamente_ no está _tan segura_ porque le perre de la imagen parece un poco une gate, pero...\n",
    "\n",
    "¿y si le pedimos que clasifique la figura de la derecha? Cualquier cosa puede pasar, nos puede dar una 'raw score' por encima o por debajo de 0.5 o exactamente 0.5, pero en cualquier caso, sabemos que no es fiable. Y la cuestión es que **el modelo de aprendizaje automático no nos podría decir 'hey, no tengo ni idea' porque las 'raw scores' no muestran certidumbre**, a pesar de lo que todes hemos erróneamente interpretado alguna vez.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa08397",
   "metadata": {},
   "source": [
    "![tweet_uq](./images/tweet_uq.png \"tweet_uq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d20db",
   "metadata": {},
   "source": [
    "En una tarea de regresión ocurre lo mismo. Entrenamos el modelo con un gran conjunto de datos de precios de casas y al aplicarlo sobre una casa nos da cómo resultado, por ejemplo, 135.896,73 euros. La probabilidad de que el precio verdadero de la casa sea ese es nula. Si el modelo rinde bien, el precio verdadero estará cerca de ese valor, estará dentro de un intervalo de predicción alrededor de ese valor. Cuanto más ancho el intervalo, más grande la incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56811a2f",
   "metadata": {},
   "source": [
    "Y es importante recordar que los modelos de aprendizaje automático supervisado están diseñados para interpolar, **no para extrapolar, ni para identificar relaciones de causa-efecto, ni para abstraer conocimiento,... por lo cual les cuesta generalizar y pueden caer en el atajo de basar sus predicciones en correlaciones espúreas y sin sentido**. Si no damos al modelo la oportunidad de avisarnos de que no está preparado para desempeñar la tarea, nos dará igualmente una predicción, y tomaremos que está igual de seguro de esa predicción como lo está de la predicción de una instancia estándar para la que sí está entrenado. Sería mucho más adecuado que el modelo de aprendizaje automático nos informara de la certeza de sus resultados.  \n",
    "\n",
    "Saber qué no sabemos, i.e, cuantificar la incertidumbre, mejora la calidad de las decisiones para poder descartar las predicciones con alta incertidumbre y derivar las decisiones a expertes humanos, como ocurre en el denominado ['Active Learning'](https://en.wikipedia.org/wiki/Active_learning_(machine_learning)). Como ejemplo, el vídeo del artículo [Robots That Ask For Help](https://robot-help.github.io/) de les desarrolladores del Large Language Model de Google, donde cuantifican incertidumbre con Predicción Conforme, el método que explicamos en la sección <a href=#app-uq>4. Aplicación de métodos de cuantificacion de incertidumbre</a><br>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e08e5",
   "metadata": {},
   "source": [
    "<font color=#6B8E23 size=\"3\">Ejemplos mostrando que las métricas de rendimiento como \"accurary\" no son suficientes y no indican certeza</font>\n",
    "\n",
    "+ [Métrica incorrecta](https://koaning.io/posts/goodheart-bad-metric/), sobre la [ley de Goodhart](https://es.wikipedia.org/wiki/Ley_de_Goodhart): \"cuando la métrica se convierte el objetivo a optimizar, pierde su valor\"\n",
    "+ [La optimización métrica no es suficiente](https://koaning.io/posts/high-on-probability-low-on-certainty/),\n",
    "+ [Mean Squared Terror](https://koaning.io/posts/mean-squared-terror/),\n",
    "+ [Accuracy as a Failure](https://www.infoq.com/presentations/project-failure-data-accuracy/),\n",
    "+ [How to calibrate your classifier in an intelligent way using Machine Learning Conformal Prediction](https://valeman.medium.com/how-to-calibrate-your-classifier-in-an-intelligent-way-a996a2faf718),\n",
    "+ [Correlaciones espúreas divertidas](http://www.tylervigen.com/spurious-correlations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d27fe",
   "metadata": {},
   "source": [
    "#### <font color=#ac6240>1.1.1 Definición de Incertidumbre</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6295a91",
   "metadata": {},
   "source": [
    "Según la Wikipedia en castellano (consultada el 26.09.2022):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d000d",
   "metadata": {},
   "source": [
    "![uncertainty_wp](./images/uncertainty_wp.png \"uncertainty_wp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c94da",
   "metadata": {},
   "source": [
    "[Fuente de la imagen](https://es.wikipedia.org/wiki/Incertidumbre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b04b2b",
   "metadata": {},
   "source": [
    "Vamos, que el asunto va de lo que pasa cuando queremos medir u observar algo o predecir cuánto valdrá algo. \n",
    "\n",
    "Consultemos ahora a les expertes en [metrología](https://es.wikipedia.org/wiki/Metrolog%C3%ADa), es decir, la Oficina Internacional de Pesas y Medidas ([BIPM](https://www.bipm.org/en/committees/jc/jcgm/), por sus siglas en francés) cuyo Joint Committee for Guides in Metrology (JCGM) publica la Guía para la expresión de la Incertidumbre en la Medida (GUM, por sus siglas en inglés) que incluye el International Vocabulary of basic and general terms in Metrology ([VIM](https://www.bipm.org/en/committees/jc/jcgm/publications) JCGM_100_2008_E-1)\n",
    "\n",
    "<font size=\"5\">🤪🤯</font>\n",
    "\n",
    "\n",
    "donde se define:\n",
    "\n",
    "<blockquote>\n",
    "\n",
    "**2.2 The term 'uncertainty'**\n",
    "\n",
    "[...] Uncertainty (of measurement) [is a] parameter, associated with the result of a measurement, that characterizes the dispersion of the values that could reasonably be attributed to the measurand. [...] The parameter may be, for example, a standard deviation (or a given multiple of it), or the half-width of an interval having a stated level of confidence.\n",
    "</blockquote>\n",
    "\n",
    "y también:\n",
    "\n",
    "<blockquote>\n",
    "    \n",
    "**3.3. Uncertainty**\n",
    "\n",
    "The uncertainty of the result of a measurement reflects the lack of exact knowledge of the value of the measurand.\n",
    "</blockquote>\n",
    "\n",
    "Antes de ver qué significa esto en el contexto del aprendizaje automático, hagamos una aclaración importante para distinguir bien entre los conceptos de incentidumbre, error, residuo y sesgo o 'bias'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609d9df",
   "metadata": {},
   "source": [
    "#### <font color=#ac6240>1.1.2 Incertidumbre vs error vs residuo vs bias</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab9a51",
   "metadata": {},
   "source": [
    "El **error** es la diferencia entre el valor verdadero, (asumiento que existe y se puede definir, ojo, que aquí esto es clave), y el valor resultado de la medición o predicción, por ejemplo, realizada empíricamente con un aparato de medida o en nuestro caso, el dato de si le paciente sufre o no fallo cardíaco. \n",
    "\n",
    "Si ese valor verdadero lo defimos por un modelo, esa diferencia entre la medición y el modelo también se llama **residuo**, por ejemplo, la distancia entre un punto `(x,y)` (el dato resultado de la medición) y la recta de regresión lineal que intenta representar a todos los datos, `y = mx + n`, y que idealizamos como representación de la realidad. Vimos la regresión lineal brevemente en la seccion 4.1 Modelo de referencia inicial para la selección de la métrica: Regresión Logística del Jupyter Notebook `Exploration_and_Classification.ipynb`.\n",
    "\n",
    "Entonces, en la representacion tradicional, la desviación entre el valor obtenido de la medición y el ansiado supuesto valor verdadero se compone de dos tipos de errores:\n",
    "+ el error aleatorio, la componente debida a la naturaleza [estocástica](https://en.wikipedia.org/wiki/Stochastic_process#Examples) del sistema, y\n",
    "+ el error sistemático, también llamado **sesgo o 'bias'**, que es la componente reducible porque su media no es cero y se puede compensar con un 'factor de correccion' (mencionamos los problemas éticos del sesgo en IA en la intro del Jupyter Notebook `XAI.ipynb`).\n",
    "\n",
    "En la Introducción del nuevo informe de 2012 [VIM 200:2012](https://www.bipm.org/en/committees/jc/jcgm/publications) se indica que estos dos tipos de errores no siempre son fáciles de diferenciar y que no disponemos de una regla general para ver cómo se combinan. Y también dice que normalmente estimamos el límite superior del valor absoluto del error total y que llamamos vagamente a eso 'incertidumbre'.\n",
    "\n",
    "Pero la VIM también nos indica que es mejor no seguir ese punto de vista tradicional del 'error' porque:\n",
    "\n",
    "+ necesita de la asumpción de la existencia un 'valor verdadero', y \n",
    "+ su objetivo es minimizar cualquier diferencia entre el resultado de la medida y ese supuesto 'valor verdadero', porque considera el error como una imperfección indeseable,\n",
    "\n",
    "siendo más adecuado tratar la dispersión de los resultados de las mediciones como una 'incertidumbre' que:\n",
    "\n",
    "+ aporta valiosa información y detalles significativos del comportamiento del sistema, y \n",
    "+ nos permite asumir que **la medición solo se puede expresar como un intervalo de valores razonables**.\n",
    "\n",
    "<font size=\"5\"> 👏 </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc74797e",
   "metadata": {},
   "source": [
    "Veamos ahora a qué nos referimos con \"intervalo de valores razonable\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad81592",
   "metadata": {},
   "source": [
    "#### <font color=#ac6240>1.1.3 Intervalo de valores razonables</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b7dae",
   "metadata": {},
   "source": [
    "Hay muchas maneras de definir qué entendemos por un 'intervalo de valores razonables' que nos permita cuantificar la posible variabilidad de los resultados y por tanto, la incertidumbre de la medición.\n",
    "\n",
    "Los métodos de UQ que aquí explicamos nos proveen de un [intervalo de predicción](https://en.wikipedia.org/wiki/Prediction_interval) para cada predicción, es decir, es una estimación del rango de valores que con la probabilidad que determinamos con el llamado 'nivel de confianza' (por ejemplo, con 0.90 tendremos el 90% de probabilidad) incluirá el valor correcto. \n",
    "\n",
    "Cuanto más estrecho es el intervalo de predicción, más podemos confiar en la predicción. Por ejemplo, data una predicción, `y_pred = 100`, calculamos su intervalo de predicción para que contenga al valor verdadero con un 90% de probabilidad. Si obtenemos el intervalo [99, 101] confiamos en el resultado más que si obtenemos el intervalo [50, 120].\n",
    "\n",
    "###### Diferencias entre intervalos\n",
    "[Intervalos de predicción](https://en.wikipedia.org/wiki/Prediction_interval): los que calculamos con Predicción Conforme, el método que explicamos en la sección <a href=#app-uq>4. Aplicación de métodos de cuantificacion de incertidumbre</a>, con garantía estadística contienen a la \"ground truth\", i.e., cumplen \"validity\", también llamada \"garantía de cobertura\". Si la tarea es de clasificación, se llaman conjuntos de predicción e incluyen la true label.\n",
    "\n",
    "[Intervalos de confianza](https://es.wikipedia.org/wiki/Intervalo_de_confianza) de la estadística frecuentista: asociados a la incertidumbre al estimar un parámetro de la población (por ejemplo, el valor esperado) a partir de un muestreo (por ejemplo, la media). Indican también un rango pero en ese caso indica una dispersión alrededor del parámetro estimador, no la incertidumbre de una predicción individual. El ejemplo clásico es el intervalo de confianza calculado con la desviación estándar alrededor de la media de varias predicciones: `[y_mean - y_std, y_mean + y_std]`. No cumplen \"validity\".\n",
    "\n",
    "[Intervalos de credibilidad](https://es.wikipedia.org/wiki/Intervalo_cre%C3%ADble) de los posteriores en la estadística bayesiana: incluyen la predicción con una probabilidad determinada, es decir, tratan sus límites como fijos y la predicción como una variable aleatoria (los intervalos de confianza frecuentista tratan sus límites como variables aleatorias y la predicción como un valor fijo).  Requieren el conocimiento de la distribución a priori que es específica de los inputs de cada situación (algo para nada sencillo). No cumplen \"validity\".\n",
    "\n",
    "Aquí nos centramos en cómo calcular intervalos de predicción para las predicciones arrojadas por modelos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53585389",
   "metadata": {},
   "source": [
    "#### <font color=#ac6240>1.1.4 Incertidumbre en aprendizaje automático</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f4913",
   "metadata": {},
   "source": [
    "Como decíamos, cuando aplicamos un modelo de aprendizaje automático es muy desable que no solo nos ofrezca una \"raw score\" (por ejemplo, la puntuación cruda que sale de la última capa de activación de una red neuronal) sino que nos diga además cuándo no está seguro y cuánta incertidumbre está asociada a su predicción. \n",
    "\n",
    "Podriamos incluso intentar desglosar los tipos de incertidumbre según su origen. Por ejemplo, puede haber incertidumbre:\n",
    "+ en cómo se tomaron y procesaron los datos que usamos, la precisión de los aparatos de observación y medida, el etiquetado, el almacenamiento, el ruido externo que hubo durante el proceso de recolección de esos datos, ... \n",
    "+ en el elección del modelo: diseño, estimación de parámetros, tipo de regularizacion, tipo de optimización, selección de métricas, ..., \n",
    "+ en el error humano, el desconocimiento, los [sesgos cognitivos](https://www.visualcapitalist.com/50-cognitive-biases-in-the-modern-world/),...\n",
    "\n",
    "y un millón de factores más."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d3e607",
   "metadata": {},
   "source": [
    "Las fuentes de incertidumbre es un tema muy importantes pero demasiado complicado para un taller general como este porque requiere 'domain expertise' para cada caso. Aquí nos centramos en la incertidumbre en la predicción y simplemente mencionaremos que en aprendizaje automático se suelen considerar [dos tipos de incertidumbre](https://deepai.org/publication/aleatoric-and-epistemic-uncertainty-in-machine-learning-a-tutorial-introduction) en la predicción que se pueden resumir en:\n",
    "\n",
    "+ Aleatoria: \"¿saldrá cara o cruz si lanzo una moneda al aire?\", incertidumbre relativa al dato individual, **que no es reducible**, ni aunque aumentamos el número de datos con el que entrenamos el modelo de aprendizaje automático, y\n",
    "\n",
    "+ Epistémica: \"¿me fío de que esta moneda no está trucada?\", incertidumbre relativa a la certeza del modelo de aprendizaje automático después de haber visto la instancia cuya 'target' ha de predecir, **sí se puede reducir** con más datos de entrenamiento.\n",
    "\n",
    "En general, la incertidumbre aleatoria está relacionada con lo que llamamos \"varianza natural del fenómeno\", que es la imposibilidad de conocer y controlar todos los factores e interacciones físicas y naturales de ese fenómeno en el mundo real. Porque si conociéramos todos los factores físicos de ese lanzamiento (peso, forma, y posición exacta de la moneda, ángulo y fuerza de lanzamiento, ecuaciones dinámicas, velocidad del viento, densidad del aire, ...), es decir, si fuésemos el [Demonio de Laplace](https://es.wikipedia.org/wiki/Demonio_de_Laplace), podríamos predecir con absoluta certeza si resultado es cara o cruz. Sería una falta de [conocimiento o episteme](https://dle.rae.es/episteme), así que tendríamos que atribuir parte de la incertidumbre aleatoria a la incertidumbre epistémica y las barreras entre ambas se diluyen.\n",
    "\n",
    "<font size=\"5\"> 😬😅 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ee85f",
   "metadata": {},
   "source": [
    "Pero la cosa se complica aún más porque en realidad hay un tercer tipo de incertidumbre a tener en cuenta en aprendizaje automático y que está relacionado con el [sesgo inductivo](https://es.wikipedia.org/wiki/Sesgo), es decir, cómo trata el algoritmo aquellas preguntas para las que no ha sido entrenado.:\n",
    "\n",
    "+ 'Drift' también conocido como 'Shift': \"¿sigo aún lanzando la misma moneda?\", incertidumbre relacionada con los cambios en la distribución de datos, cuando los nuevos datos no tienen la misma distribución que tenian los datos de entrenamiento (como dijimos anteriormente, para amplicar sobre la definición y sus diferentes tipos, [aquí](https://analyticsindiamag.com/concept-drift-vs-data-drift-in-machine-learning/)). La librería [NannyML](https://github.com/NannyML/nannyml) sirve para detectarlo.\n",
    "\n",
    "Ejemplos de 'drift' son cambios en la resolución de la camara que hace las fotos para la clasificación de imagenes, la persona que etiqueta los datos para una clasificación, los gustos de les clientes para un 'sentiment analysis', ... o incluso la aparición de nuevos fenómenos, pensemos en la dificultad en la predicción de los efectos de cambio climático ya que los modelos de aprendizaje automático se basan en datos históricos recogidos cuando las temperaturas globales no eran tan altas. En otras palabras, los modelos no pueden conocer más allá de los datos con los que han sido entrenados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39cb9d6",
   "metadata": {},
   "source": [
    "![comic_uq](./images/comic_uq.png \"comic_uq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7043034",
   "metadata": {},
   "source": [
    "[Fuente de la Imagen](https://www.smbc-comics.com/comic/rise-of-the-machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b076ea3",
   "metadata": {},
   "source": [
    "<font color=#6B8E23 size=\"4\"> Conclusión</font>\n",
    "\n",
    "+ Las decisiones basadas en predicciones deben tener en cuenta la incertidumbre. Por ejemplo, dada una predicción `y = 100`, es bueno saber si el intervalo de predicción es [99, 101] o [50, 120] para poder planear mejor los posibles escenarios, sobre todo al automatizar procesos sensibles o de riesgo.\n",
    "\n",
    "+ Sin cuantificación de la incertidumbre las buenas y las malas predicciones parecen iguales. La cuantificación de la incertidumbre ofrece a los modelos de aprendizaje automático la posibilidad de expresarse mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6852f",
   "metadata": {},
   "source": [
    "<font color=#6B8E23 size=\"4\"> Material adicional y referencias</font>\n",
    "\n",
    "<font color=#6B8E23 size=\"3\">Ejemplos de los peligros de la 'single-point prediction'</font>\n",
    "\n",
    "+ La espectacular charla del gran Vincent Warmerdamm ['How to constrain artificial stupidity'](https://youtu.be/Z8MEFI7ZJlA).\n",
    "\n",
    "+ El libro _'Weapons of math destruction'_ de Cathy O'Neil, hay [versión en castellano](https://www.indienauta.com/armas-destruccion-matematica-cathy-oneil-capitan-swing-2018/)\n",
    "\n",
    "+ El libro ['Algorithms of Oppression'](https://en.wikipedia.org/wiki/Algorithms_of_Oppression) de Safiya Noble.\n",
    "\n",
    "<font color=#6B8E23 size=\"3\">Conceptos de UQ</font>\n",
    "\n",
    "+ En este blog, el articulo: [_\"A Comprehensive Introduction to Uncertainty in Machine Learning\"_](https://imerit.net/blog/a-comprehensive-introduction-to-uncertainty-in-machine-learning-all-una/#:~:text=One%20way%20to%20estimate%20aleatoric,create%20a%20subset%20of%20samples), muy bueno, pero por desgracia no incluye los 'Conformal Predictors', nuestra herramienta favorita porque es la única que garantiza la cobertura, como explicamos más abajo, sección <a href=#uq-cp>4.1 Conformal Predictors</a>,\n",
    " \n",
    "+ La referencia por definición, el libro gratuito [_\"Probabilistic Machine Learning: Advanced Topics\"_](https://probml.github.io/pml-book/book2.html), desde 2022 por fín incluye los 'Conformal Predictors', aún no leí el libro completo pero tengo que hacerlo.\n",
    "\n",
    "<font size=\"5\"> 😅 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847fd79",
   "metadata": {},
   "source": [
    "Continuamos con la preparación de los datos y el entrenamiento del modelo de aprendizaje automático. Si ya trabajaste con los dos Jupyter Notebooks anteriores de este taller y estás familiarizade con los datos y el modelo del bosque aleatorio, puedes pasar directamente a las seccion <a href=#app-uq>4. Aplicación de métodos de cuantificación de incertidumbre</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364261e",
   "metadata": {},
   "source": [
    "<a name='project-description-goal'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249c5d6",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### <font color=#ac6240>1.2 Objetivo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a5f36",
   "metadata": {},
   "source": [
    "En este Jupyter Notebook vamos a aprlicar UQ a los resultados del modelo de bosque aleatorio (que no es interpretable) que entrenamos en el Jupyter Notebook `Exploration_and_Classification.ipynb`. No incluimos explicaciones exhaustivas y demostraciones matemáticas (hay muchas otras fuentes, ver la lista de materiales arriba), mejor mencionaremos algunas características intuitivas sobre la cuantificación de la incertidumbre y nos enfocaremos en su implementación en Scikit-learn y software compatible.\n",
    "\n",
    "Como dijimos, si ya conoces alguno de los dos Jupyter Notebook anteriores ya estarás familiarize con los datos y con el bosque aleatorio, puedes pasar directamente a la sección <a href=#app-uq> 4. Aplicación de métodos de cuantificación de incertidumbre</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f2255",
   "metadata": {},
   "source": [
    "<a name='project-description-data'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f82c3",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>1.3 Datos y modelo de aprendizaje automático</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb462c",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Utilizaremos los datos y el modelo de aprendizaje automático del Jupyter Notebook `Exploration_and_Classification.ipynb` que se encuentra en [este repositorio](https://github.com/MMdeCastro/Uncertainty_Quantification_XAI).\n",
    "\n",
    "**Datos**\n",
    "\n",
    "Utilizaremos los datos del [Conjunto de datos de predicción de insuficiencia cardíaca de Kaggle](https://www.kaggle.com/fedesoriano/heart-failure-prediction) (cita: fedesoriano. (Septiembre de 2021) Heart Failure Prediction Dataset), y\n",
    "\n",
    "Recordamos que las 'features' o características son los datos de lxs paciente ('Age', 'Cholesterol',...) y la variable objetivo o 'target', es decir, lo que queremos predecir, se llama \"HeartDisease\", y es una variable binaria que toma los valores:\n",
    "+ 1: sí, pacientes que sí presentan riesgo de padecer una cardiopatía\n",
    "+ 0: no, pacientes que no presentan riesgo de padecer una cardiopatía\n",
    "\n",
    "En relacion a la 'feature' 'Sex', vamos a interpretar que se refiere al sexo con el que nacieron esas personas. Por otro lado vemos que solo toma los valores 'M' (male) or 'F' (female), es decir, entendemos que no hay datos de personas intersexuales o no binarias.\n",
    "\n",
    "**Modelo de aprendizaje automático para la clasificación**\n",
    "\n",
    "El modelo de clasificación que utilizaremos es un bosque aleatorio que ya ajustamos, entrenamos, y validamos en el Jupyter Notebook anterior `Exploration_and_Classification.ipynb`. En este Jupyter Notebook directamente dividiremos el conjunto de datos en datos de entrenamiento y datos de prueba ('test'). Sobre esos datos de prueba aplicaremos el modelo de aprendizaje automático en la sección <a href=#model-ml>3. Aplicación del modelo de aprendizaje automático: Bosque Aleatorio</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3e965",
   "metadata": {},
   "source": [
    "Para cada nueve paciente, el modelo supervisado del bosque aleatorio anteriormente entrenado al aplicar `.predict_proba()` nos da una puntuación o 'raw score' que si esta cerca de '0' clasifica a ese paciente en el grupo de pacientes sin riesgo a sufrir fallo cardíaco y si esta cerca de '1' clasifica a ese paciente en el grupo de pacientes sin riesgo a sufrir fallo cardíaco (donde 'cerca' se define por el 'umbral de decisión' como explicamos en el anterior Jupyter Notebook `Exploration_and_Classification.ipynb`, sección 4. Entrenamiento de los modelos). \n",
    "\n",
    "Como mencionamos en la 'Observación importante' de esa misma sección 4. Entrenamiento de los modelos, las librerías más populares de Python (Scikit-learn, XGBoost, ... ) púntuan las prediciones con el método `.predict_proba()` que, a pesar de su nombre, en realidad no produce probabilidades (ver por ejemplo, el artículo [_\"Are you sure that's a probability?\"_](https://kiwidamien.github.io/are-you-sure-thats-a-probability.html)). En Keras `.predict_proba()` quedó obsoleto desde TensorFlow 2.6, hay que usar `.predict()`, en Torch sería por ejemplo, `torch.sigmoid()` para nuestro caso binario. A menudo se toma esa 'raw score' como la probabilidad de que ese nueve paciente esté o no en riesgo de sufrir una insuficiencia cardíaca. Como veremos en la sección <a href=#app-uq>4. Cuantificación de Incertidumbre</a>, estas puntuaciones son solo heurísticas, no están calibradas, y no son por tanto verdaderas probabilidades. \n",
    "\n",
    "Entonces, en siguiendo el flujo de operaciones estándard (i.e., sin cuantizar la incertidumbre aún), una vez obtenidas esas \"raw scores\", si el resultado de aplicar el modelo de aprendizaje automático sobre los datos de une paciente nos arroja una puntuación o 'raw score' de 0.7, si el umbral de decisión es igual a 0.4, le paciente quedará clasificade como 'perteniente al grupo en riesgo de sufrir fallo cardíaco'.\n",
    "\n",
    "Y volvemos a remarcar que nuestro modelo solo es bueno encontrando correlaciones, (ni generaliza, ni entiende de relaciones de causa-efecto, ni conoce las restricciones del problema,...) por eso es fundamental que las decisiones finales sean tomadas por personas expertas en medicina. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcefe57",
   "metadata": {},
   "source": [
    "![ivory](./images/ivory_small.png \"ivory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db36cc56",
   "metadata": {},
   "source": [
    "[Fuente de la imagen: \"Mean-squared-terror\"](https://koaning.io/posts/mean-squared-terror/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ca935",
   "metadata": {},
   "source": [
    "Y como es claramente una decisión de vida o muerte y como el bosque aleatorio no es un modelo interpretable, además de aplicar métodos de XAI que explicamos en el Jupyter Notebook anterior, aplicaremos aquí métodos de UQ para dar una distribución de probabilidad rigurosa a los resultados que nos indique como de seguro está el modelo de aprendizaje automático de su predicción. Lo haremos en la siguiente sección <a href=#app-uq>4. Aplicación de métodos de cuantificación de incertidumbre.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2cf6f",
   "metadata": {},
   "source": [
    "Hemos elegido trabajar sobre un conjunto de datos tabulares porque los modelos de aprendizaje automático y los métodos de UQ suelen ser más fáciles de entender si podemos ver los datos en columnas. Sin embargo los conceptos de UQ que explicamos aquí sirven para cualquier aplicación mientras sea de aprendizaje automático. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675f02f",
   "metadata": {},
   "source": [
    "<a name='project-description-software'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a856c",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>1.4 Software</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f098039",
   "metadata": {},
   "source": [
    "Usaremos estas librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d736f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     \n",
    "import numpy as np\n",
    "\n",
    "# data exploration and preparation  \n",
    "from sklearn.metrics import mutual_info_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# UQ \n",
    "#from sklearn.linear_model import QuantileRegressor\n",
    "#import nonconformist extension scikit-learn\n",
    "\n",
    "\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import accuracy_score, f1_score, auc, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "\n",
    "\n",
    "# plotting and displaying in the notebook\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "#from IPython.display import display\n",
    "#import emoji\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36066b",
   "metadata": {},
   "source": [
    "<a href=#toc>Subir a la Tabla de Contenidos</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a5965",
   "metadata": {},
   "source": [
    "<a name='prep'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac6f1a9",
   "metadata": {},
   "source": [
    "## <font color=#ac6240>2. Preparación de los datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b98480e",
   "metadata": {},
   "source": [
    "La exploración y preparación de los datos se hizo en el Jupyter Notebook `Exploration_and_Classification.ipynb` que se encuentra en [este repositorio](https://github.com/MMdeCastro/Uncertainty_Quantification_XAI), aquí solo mostarmos los pasos esenciales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97376b59",
   "metadata": {},
   "source": [
    "<a name='prep-clean'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1caef65",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>2.1 Limpieza de los datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0662a4",
   "metadata": {},
   "source": [
    "Cargamos los datos del fichero que esta en el mismo repositorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fa33de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/'  \n",
    "df = pd.read_csv(path + \"heart_failure.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214c1d3",
   "metadata": {},
   "source": [
    "'FastingBS' (la presión sanguínea en ayunas) debería ser una variable categórica ya que los valores actuales de '0' y '1' son solamente representaciones de valores cualitativos que no queremos que el modelo interprete como valores cuantitativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f1e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the categorical values wrongly classified as numericals\n",
    "new_values = {\n",
    "    0: 'L', # low\n",
    "    1: 'H', # high\n",
    "}\n",
    "\n",
    "df.FastingBS = df.FastingBS.map(new_values)\n",
    "# type(df.FastingBS[0]) # uncomment to check that it is a string type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8553d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in different lists the names of the categorical and numerical columns since they will be treated different \n",
    "categorical = df.select_dtypes(include=['object']).columns.tolist()  # for strings \n",
    "numerical = df.select_dtypes(include=['int64','float64']).columns.tolist() # for numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db8e25b",
   "metadata": {},
   "source": [
    "Los valores mínimos de 'RestingBP' y 'Cholesterol' son cero, lo cual es sospechoso. Con experiencia en el campo de la medicina, podríamos decidir si reemplazar estos valores nulos por la media u otro valor. Carecemos de esta información, por lo tanto, simplemente eliminamos esas filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04fb9793",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_drop = list(df.loc[(df.RestingBP == 0) | (df.Cholesterol == 0)].index)\n",
    "df.drop(index_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c1b95",
   "metadata": {},
   "source": [
    "<font size ='5'> ✌️ </font>No hay necesidad de más limpieza de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6113d7",
   "metadata": {},
   "source": [
    "<a name='prep-split'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f89f27",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### <font color=#ac6240>2.2 División de los datos en conjuntos de datos de entrenamiento, calibración y prueba</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305c991",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "En esta división aleatoria, y en todas las ocasiones siguientes en las que usemos un generador de números aleatorios, fijamos la semilla del generador de números aleatorios para asegurar la reproducibilidad de los resultados. Fijamos el `random_state = 1` pero podría ser 2 o cualquier otro valor, no afectará a los resultados, pero con esta corrección siempre obtendremos exactamente los mismos resultados.\n",
    "\n",
    "Recordamos que dividimos el conjunto de datos en entrenamiento, calibración, y prueba porque la exploración de los datos y el ajuste y la validación del modelo de clasificación ya lo hicimos en el Jupyter Notebook `Exploration_and_Classification.ipynb` que se encuentra en [este repositorio](https://github.com/MMdeCastro/Uncertainty_Quantification_XAI).\n",
    "\n",
    "Para poder cuantizar la incertidumbre, necesitamos guardar unos datos que nos ayuden a calibrar el modelo, por eso hacemos una segunda partición del conjunto de entrenamiento y lo separamos en 'proper train' y 'cal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024bc614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the original dataframe so further manipulations will not affect it \n",
    "df_select = df.copy() \n",
    "categorical = df_select.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical = df_select.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "numerical.remove('HeartDisease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66fd7a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b473b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716, 358, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first separate the train from the test set\n",
    "df_train, df_test = train_test_split(df_select, test_size=0.04, random_state=1)\n",
    "df_proper_train, df_cal = train_test_split(df_train, test_size=0.5, random_state=1)\n",
    "\n",
    "len(df_train), len(df_cal), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89f65631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "df_proper_train = df_proper_train.reset_index(drop=True)\n",
    "# define the target\n",
    "y_proper_train = df_proper_train.HeartDisease.values\n",
    "# remove the target from the features\n",
    "del df_proper_train['HeartDisease']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bcd55a",
   "metadata": {},
   "source": [
    "<a name='prep-encoding'/>       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a67de6",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### <font color=#ac6240>2.3 Codificación y normalización de las 'features'</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa2f6b4",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Para codificar las características categóricas usamos Scikit-Learn `DictVectorizer`, que toma un diccionario y lo convierte en un vector, es decir, en un `numpy.array`. Es un método de los llamados One-Hot Encoding (OHE) para convertir las características categóricas (no afectaría las numéricas si se lo aplicasemos) en columnas con valores binarios, con tantas columnas como valores tome la variable categórica. Por ejemplo, la columna de la caracteristíca 'ExcerciseAngina' que podía tener valores 'N' o 'Y' ahora dará lugar a dos columnas, una llamada 'ExcerciseAngina=N' y otra 'ExcerciseAngina=Y' que claramente son dependientes (dan la misma información) y están totalmente correlacionadas (cuando el valor de una es '0', el valor de la otra es seguro '1', ver las correlaciones en el Jupyter Notebook anterior). Cualquier método de codificación añade por tanto información redundante. Hemos de eliminar la información redundante desechando una de las columnas de cada par correlacionado (da igual qué columna de cada par eliminemos, ambas dan la misma información), quitaremos 'ExerciseAngina=N', 'FastingBS=H', 'Sex=F', 'ST_Slope=Up':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c576a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False) # False bcs is not a sparse matrix (we do not have many zeros)\n",
    "\n",
    "# TRAIN\n",
    "proper_train_dict = df_proper_train[categorical].to_dict(orient='records') # records = to do it row-wise, not col-wise\n",
    "X_proper_train_cat = dv.fit_transform(proper_train_dict) # make it a vector\n",
    "\n",
    "df_X_proper_train_cat = pd.DataFrame(X_proper_train_cat,columns= dv.get_feature_names_out())\n",
    "# remove redundant columns\n",
    "df_X_proper_train_cat.drop(['ExerciseAngina=N', 'FastingBS=H', 'Sex=F', 'ST_Slope=Up'], \n",
    "                    axis=1, inplace=True)\n",
    "# convert the dataframe to a np.array again\n",
    "X_proper_train_cat = df_X_proper_train_cat.to_numpy()\n",
    "\n",
    "categorical_update = df_X_proper_train_cat.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550b807",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "En el Jupyter Notebook de la exploración y clasificación de los datos usamos Scikit-Learn `StandardScaler` para normalizar las características numéricas entre 0 y 1. Así, aquellas columnas con valores en un rango más alto no tendrían más representación y modelos como la regresión logística convergían mejor. Como aquí usamos un bosque aleatorio, no necesitamos escalar las 'features' numéricas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21a24322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "\n",
    "# TRAIN\n",
    "X_proper_train_num = df_proper_train[numerical].values\n",
    "#X__propertrain_num = scaler.fit_transform(X_proper_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef815080",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Unimos las matrices numéricas y categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede9d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "X_proper_train = np.column_stack([X_proper_train_num, X_proper_train_cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31c939",
   "metadata": {},
   "source": [
    "Las nuevas características son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c5c6fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'RestingBP',\n",
       " 'Cholesterol',\n",
       " 'MaxHR',\n",
       " 'Oldpeak',\n",
       " 'ChestPainType=ASY',\n",
       " 'ChestPainType=ATA',\n",
       " 'ChestPainType=NAP',\n",
       " 'ChestPainType=TA',\n",
       " 'ExerciseAngina=Y',\n",
       " 'FastingBS=L',\n",
       " 'RestingECG=LVH',\n",
       " 'RestingECG=Normal',\n",
       " 'RestingECG=ST',\n",
       " 'ST_Slope=Down',\n",
       " 'ST_Slope=Flat',\n",
       " 'Sex=M']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = numerical + categorical_update\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0570ccfa",
   "metadata": {},
   "source": [
    "<font size=\"5\"> 👏 </font>  Ya tenemos todo para entrenar nuestro bosque aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd54a62",
   "metadata": {},
   "source": [
    "<a href=#toc>Subir a Tabla de Contenidos</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b019fd",
   "metadata": {},
   "source": [
    "<a name='model-ml'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c887bb84",
   "metadata": {},
   "source": [
    "## <font color=#ac6240>3. Aplicación del modelo de aprendizaje automático: Bosque Aleatorio</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fbeeb",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Entrenaremos el modelo de aprendizaje supervisado llamado bosque aleatorio ('Random Forest') que es uno de los clasificadores de aprendizaje automático más populares (ver, por ejemplo, [Kaggle 2021](https://storage.googleapis.com/kaggle-media/surveys/Kaggle's%20State%20of%20Machine%20Learning%20and%20Data%20Science%202021.pdf) página 32). En el Jupyter Notebook `Exploration_and_Classification.ipynb` que se encuentra en [este repositorio](https://github.com/MMdeCastro/Uncertainty_Quantification_XAI) probamos varios modelos de clasificación y el bosque aleatorio resultó ser el ganador.\n",
    "\n",
    "El bosque aleatorio es un tipo de [Ensemble Learning](https://en.wikipedia.org/wiki/Ensemble_learning): corremos en paralelo muchos árboles de decisión y tomamos la predicción del que obtuvo más aciertos. Primero, se crean múltiples conjuntos de datos de entrenamiento mediante el muestreo de datos del conjunto de datos de entrenamiento (un método conocido como 'bootstrapping' o 'bagging') y luego se entrena un árbol de decisión en cada uno de estos conjuntos de datos.  Pueden usarse para resolver problemas de regresión o de clasificación. Por lo general, los bosques aleatorios tienen un alto rendimiento, pero no son interpretables (son 'black-boxes') y no son recomendables para grandes conjuntos de datos (~ TB) porque requieren mucha más potencia de computadora que la regresión logística, por ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92daf3",
   "metadata": {},
   "source": [
    "<a name='model-metric'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd33785",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>3.1 Selección de la Métrica y del umbral de decisión</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7f180",
   "metadata": {},
   "source": [
    "En el Jupyter Notebook `Exploration_and_Classification.ipynb` que se encuentra en [este repositorio](https://github.com/MMdeCastro/Uncertainty_Quantification_XAI), decidimos medir la calidad del modelo con la metrica denominada 'F1-score' porque **queremos evitar los Falsos Negativos (no queremos diagnostiar como sane a une paciente en riesgo)**. Además, contaremos la tasa de Verdaderos Positivos (o 'recall') y no perderemos de vista la precisión ('precision') y exactitud ('accuracy').\n",
    "\n",
    "\n",
    "Por último, concluimos que definíamos el umbral de decisión en `t = 0.4`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea26f4b",
   "metadata": {},
   "source": [
    "<a name='model-RF'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cdf592",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>3.2 Entrenamiento, prueba, y aplicación del bosque aleatorio</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5dfa7",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "No vamos a repetir todo el proceso de ajuste y validación sino que directamente entrenamos y probamos ('test') el modelo de clasificación para poder comenzar la cuantificación de la incertidumbre en el siguiente apartado. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a97f9",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "#### <font color=#ac6240>3.2.1 Entrenamiento y prueba del bosque aleatorio</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f039304",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Entrenamos el modelo ganador con los datos de entrenamiento: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44d36ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the machine learning model: random forest\n",
    "\n",
    "RF = RandomForestClassifier(max_depth = 10, min_samples_leaf = 5, \n",
    "                            n_estimators =  50, random_state = 1)\n",
    "\n",
    "model = RF.fit(X_proper_train, y_proper_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50fbcce",
   "metadata": {},
   "source": [
    "Vamos aplicarlo sobre los datos de prueba, primero los preparamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd3435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation TEST data\n",
    "\n",
    "# reset index after the splitting shuffling\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "# define target of the test set\n",
    "y_test = df_test.HeartDisease.values\n",
    "   \n",
    "# 1. encode the categorical features and remove redundant columns-------------    \n",
    "\n",
    "test_dict = df_test[categorical].to_dict(orient='records')\n",
    "X_test_cat = dv.transform(test_dict) \n",
    "\n",
    "# convert the data array to a dataframe\n",
    "df_X_test_cat = pd.DataFrame(X_test_cat,columns= dv.get_feature_names_out())\n",
    "\n",
    "# remove redundant columns\n",
    "df_X_test_cat.drop(['ExerciseAngina=N', 'FastingBS=H', 'Sex=F', 'ST_Slope=Up'], \n",
    "                    axis=1, inplace=True)\n",
    "\n",
    "# convert the dataframe to a np.array again\n",
    "X_test_cat = df_X_test_cat.to_numpy()\n",
    "\n",
    "# 2. scale the numerical features --------------------------------------------\n",
    "\n",
    "X_test_num = df_test[numerical].values\n",
    "#X_test_num = scaler.transform(X_test_num) \n",
    "\n",
    "# 3. join the matrices -------------------------------------------------------\n",
    "\n",
    "X_test = np.column_stack([X_test_num, X_test_cat]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052abc6",
   "metadata": {},
   "source": [
    "#### Evaluación del modelo clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7baf31d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the test dataset: ACC: 0.833 Recall: 0.846 F1: 0.815 ROC AUC: 0.887\n"
     ]
    }
   ],
   "source": [
    "# model application on TEST data\n",
    "y_pred = RF.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# metrics analysis\n",
    "t = 0.4\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred >= t) \n",
    "rec = recall_score(y_test, y_pred >= t)\n",
    "f1  = f1_score(y_test, y_pred >= t) \n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print('For the test dataset:',\n",
    "      'ACC:', acc.round(3), 'Recall:', rec.round(3),'F1:', f1.round(3),\n",
    "      'ROC AUC:', auc.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "852fa69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred >= t)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Confusion Matrix\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "ax.xaxis.set_ticklabels(['0','1'])\n",
    "ax.yaxis.set_ticklabels(['0','1'])\n",
    "\n",
    "##plt.figure(figsize=(7,5))\n",
    "plt.rcParams['figure.figsize'] = [7, 5]  # re-run this cell to get the correct figure size\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f4cdb",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "<font size=\"5\"> 👏 </font> Como es un contexto médico, queremos evitar los Falsos Negativos y hemos obtenido solo 3, con un porcentaje de aciertos de aproximadamente el 90% (ver los valores de las métricas obtenidos), no está mal. Además, vimos en el Jupyter Notebook anterior que estos hiperparametros nos dan valores de las métricas similares a los de los conjuntos de datos de entrenamiento y validación, por lo que no estamos sobreajustadando ('overfitting') y esperamos que el modelo generalice bien dentro de lo posible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d2107",
   "metadata": {},
   "source": [
    "<a href=#toc>Subir a Tabla de Contenidos</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b123247",
   "metadata": {},
   "source": [
    "#### <font color=#ac6240>3.2.2 Aplicación del bosque aleatorio</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c39ca",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Simulemos una nueva paciente con los siguientes datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac29c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_patient = {\n",
    "    'Age': 56,\n",
    "    'Sex': 'F',\n",
    "    'ChestPainType': 'ATA', \n",
    "    'RestingBP': 130,  \n",
    "    'Cholesterol': 150, \n",
    "    'FastingBS': 'L',\n",
    "    'RestingECG': 'ST',\n",
    "    'MaxHR': 115,\n",
    "    'ExerciseAngina': 'N',\n",
    "    'Oldpeak': 1.,\n",
    "    'ST_Slope': 'Flat',\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca834d",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Preparamos los datos de entrada como en la sección <a href=#prep>2. Preparación de los datos</a>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51da80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dict = dict()\n",
    "cat_dict = dict()\n",
    "    \n",
    "for (key, value) in new_patient.items():\n",
    "    if key in numerical:\n",
    "        num_dict[key] = value\n",
    "    else:\n",
    "        cat_dict[key] = value\n",
    "\n",
    "# DictVect input must be a dict\n",
    "X_cat = dv.transform(cat_dict) # encode the categorical features\n",
    "df_X_cat = pd.DataFrame(X_cat,columns= dv.get_feature_names_out()) # convert array to df\n",
    "df_X_cat.drop(['ExerciseAngina=N', 'FastingBS=H', 'Sex=F', 'ST_Slope=Up'], \n",
    "              axis=1, inplace=True) # remove redundant columns\n",
    "X_cat = df_X_cat.to_numpy() # convert the dataframe to a np.array again\n",
    "\n",
    "# Scaler input must be a np.array\n",
    "X_num = np.array(list(num_dict.values())).reshape(1, -1)\n",
    "#X_num = scaler.transform(X_num) # scale the numerical features\n",
    "\n",
    "# Join both arrays\n",
    "X = np.column_stack([X_num, X_cat]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b123ce27",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "y aplicamos el modelo de clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13c11fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Application of the Random Forest classifier to a new patient:\n",
      "\n",
      "The patient raw score of suffering a hear failure is: 0.33\n",
      "\n",
      "With t = 0.4 as the decision threshold, is there a risk of suffering a heart failure?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "y_pred = RF.predict_proba(X)[:, 1]\n",
    "print('Application of the Random Forest classifier to a new patient:')\n",
    "print()\n",
    "print(\"The patient raw score of suffering a hear failure is:\", y_pred[0].round(2))\n",
    "t = 0.4\n",
    "print()\n",
    "print(\"With t =\", t, \"as the decision threshold, is there a risk of suffering a heart failure?\")\n",
    "print(y_pred[0] >= t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f17f5",
   "metadata": {},
   "source": [
    "Empezamos ya a implementar UQ para incluir la certeza de la predicción en lugar de un único valor puntual. Identificaremos así cuando nuestro modelo no está seguro de su predicción y podremos reducir el número de Falsos Negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6960dd69",
   "metadata": {},
   "source": [
    "![Molnar_UQ](./images/Molnar_UQ.png \"Molnar_UQ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bee37a",
   "metadata": {},
   "source": [
    "[Fuente de la imagen](https://twitter.com/ChristophMolnar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945ea01",
   "metadata": {},
   "source": [
    "<a href=#toc>Subir a Tabla de Contenidos</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaf394",
   "metadata": {},
   "source": [
    "<a name='app-uq'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2931515d",
   "metadata": {},
   "source": [
    "## <font color=#ac6240>4. Cuantificacion de incertidumbre</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564ba69",
   "metadata": {},
   "source": [
    "Como mencionamos más arriba, las librerías más populares de Python (Scikit-learn, XGBoost, ... ) púntuan las prediciones con el método `.predict_proba()` que, a pesar de su nombre, en realidad no produce probabilidades (ver por ejemplo, el artículo [_\"Are you sure that's a probability?\"_](https://kiwidamien.github.io/are-you-sure-thats-a-probability.html)). En Keras `.predict_proba()` quedó obsoleto desde TensorFlow 2.6, hay que usar `.predict()`, en Torch sería por ejemplo, `torch.sigmoid()` para nuestro caso binario. \n",
    "\n",
    "Estas puntuaciones crudas o 'raw scores' que salen de la última función de activación (normalmente una sigmoid o softmax, aunque en las capas internars usaras `activation='relu'` ver por ejemplo los [docs de Scikit-learn](https://github.com/scikit-learn/scikit-learn/blob/7b136e9/sklearn/neural_network/multilayer_perceptron.py#L267\n",
    ")) van entre 0 y 1 y todas juntas suman 1 (por ejemplo, en una tarea de clasificación binaria como la del ejemplo de la sección 1.1 <a href=#project-description-intro>Introducción</a>, si una instancia obtiene 0.9 para la clase \"gate\", entonces obtiene 0.1 para la clase \"perre\") pero no por eso son probabilidades porque **no están calibradas, es decir, no es necesariamente cierto que las instancias que obtuvieron 0.9 sean un 90% \"gates\"**. Como mucho podemos considerarlas solo como 'probabilidades heurísticas' es decir, sin garantía estadística. Asumir que las 'raw scores' son verdaderamente probabilidades causa consecuencias desastrosas a la hora de inferir información o al intentar sumar estas puntuaciones a verdaderas probabilidades, como se explica en [_\"How to calibrate your classifier in an intelligent way using Machine Learning Conformal Prediction\"_](https://valeman.medium.com/how-to-calibrate-your-classifier-in-an-intelligent-way-a996a2faf718).\n",
    "\n",
    "Como decíamos, las puntuaciones están calibradas para ser verdaderas probabilidades si, por ejemplo, entre todas las clasificaciones con una puntuación del 90% encontramos la clase verdadera 9 de cada 10 veces. Por ejemplo, cuando en la sección 1.1 <a href=#project-description-intro>Introducción</a> hablábamos de la clasificación binaria de imágenes de \"perres\" (0) y \"gates\" (1) y la primera foto (que era une gate) obtenía una 'raw score' de 0.9, para que esa 'raw score' fuera una verdadera probabilidad deberíamos encontrar una foto de une gate el 90% de las veces que una foto obtuviera un 0.9 en la fase de inferencia. Para ver que así sea, hemos de calibrar esa 'raw score' con el numero de imágenes de gates que realmente había en el conjunto de datos de calibración (algo que ni el método `.predict_proba()` ni `.predict()` hacen). Lo que ocurre a menudo es que al calibrar esa 'raw score' obtenemos un nuevo valor. Por ejemplo, la verdadera puntuación (que ya es una verdadera probabilidad) de la foto de ese gate puede que pase de 0.9 a 0.7.\n",
    "\n",
    "Aquí vamos a explicar la familia de métodos denominados ['Conformal Predictors'](https://en.wikipedia.org/wiki/Conformal_prediction) los cuales funcionan para cualquier modelo de aprendizaje automático y nos permiten calibrar nuestras 'raw scores' para que sean verdaderas probabilidades y en el proceso obtendremos los intervalos de predicción tal que: \n",
    "\n",
    "+ de la 'raw score' de 0.9 para el ejemplo de la foto de le gate, obtendríamos algo como [0.75, 0.80], lo que nos da la idea de que el modelo de clasificación está bastante seguro de que es une gate, \n",
    "+ de la 'raw score' de 0.5 para el ejemplo de la foto de le perre con espuma en la cabeza, obtendríamos algo como [0.35, 0.65], lo que nos dice que no nos fiemos de ese resultado, y\n",
    "+ para la imagen de la pájaro la 'raw score' calibrada sería algo como [0.1, 0.8], es decir, algo muy poco fiable que nos avisa que no debemos confiar en esa predicción. \n",
    "\n",
    "A continuación aplicamos un ejemplo para nuestra predicción de fallo cardíaco en la sección <a href=#uq-cp>4.1 Conformal Predictors</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0fb828",
   "metadata": {},
   "source": [
    "<a name='uq-cp'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be5d38",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>4.1 Conformal Predictors</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e5c1d",
   "metadata": {},
   "source": [
    "La ['Conformal Prediction'](https://en.wikipedia.org/wiki/Conformal_prediction) es una familia de métodos para cuantizar la incertidumbre de los resultados de un modelo y saber así cuánto podemos confiar en ellos. Recibe su nombre de la denominada medida de no conformidad, o 'nonconformity measure' que cuantiza cuán diferente es la  predicción dentro del conjunto de predicciones que obtuvimos al predecir el conjunto de entrenamiento. Una alta 'nonconformity' indica que el nuevo dato es raro, como la foto de le pájare en el ejemplo de clasificación de perres y gates de la Introducción de este Jupyter Notebook. Algunos autores y autoras la llaman medida de conformidad, es lo mismo, son maneras de hablar.\n",
    "\n",
    "Las personas que aplicamos Conformal Predictions nos llamamos 'nonconformists'.\n",
    "\n",
    "\n",
    "<font size=\"5\">😎<font/>\n",
    "    \n",
    "Los miembros de la familia de la Prediccón Conforme son esencialmente calibradores de las predicciones que en el proceso de calibración generan regiones de predicción alrededor de dichas predicciones. Cuánto más estrecha es la región, más confiamos en la predicción. Si la predicción puede tomar valores contínuos, como en tareas de regresión, las regiones son intervalos, por ejemplo [49,55] y si pueden tomar valores discretos, como ocurre en clasificación, las regiones son conjuntos (\"sets\"), por ejemplo [\"gate\", \"perre\"]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21442f",
   "metadata": {},
   "source": [
    "La 'Predicción Conforme':\n",
    "\n",
    "+ es 'model-agnostic', funciona para cualquier modelo de aprendizaje automático y para cualquier tarea, ni siquiera necesita conocer al modelo de aprendizaje automático para el que está cuantizando la incertidumbre de sus predicciones,     \n",
    "+ ofrece garantía de cobertura demostrada matemáticamente: los intervalos de predicción vienen con garantías de contener el resultado verdadero dado un nivel de confianza determinada, por ejemplo, garantizan contener a la 'ground truth' el 90%, 95%, o 99% de las veces,\n",
    "+ se aplica en el 'post-processing' sobre las predicciones del modelo de aprendizaje automático ya entrenado (no hay que reentrenar el random forest, en este caso), es decir, una vez obtenidas las predicciones, las conformalizamos,\n",
    "+ requiere pocas líneas de código y es rápida, \n",
    "+ funciona para datos recogidos en tiempo real, es decir, 'online assimilation',\n",
    "+ a diferencia de los métodos paramétricos, no es necesario asumir que la variable de destino o 'target' está distribuida según una cierta distribución (casi nada en el universo puede aproximarse a una distribución normal y recordemos que el Teorema del Límite Central no indica eso, lo que indica es que las _medias_ de las distribuciones se aproximan a una distribución normal).\n",
    "\n",
    "De hecho, la única condición para garantizar la cobertura de los intervalos de predicción calculados con 'Conformal Prediction' es que las instancias sean [intercambiables](https://en.m.wikipedia.org/wiki/Exchangeable_random_variables), es decir, que el orden de los datos no importe, (como en nuestro caso, el clasificador Random Forest no requiere que les pacientes estén ordenades, cualquier ordenación de les pacientes arrojará estadísticamente el mismo resultado) lo cual es una restricción menos fuerte que la típica restricción sobre que los datos han de ser independientes e estar idénticamente distributidos o [iid](https://es.wikipedia.org/wiki/Variables_aleatorias_independientes_e_id%C3%A9nticamente_distribuidas). Aunque desde 2021 ya hay algoritmos de CP para confomalizar series temporales (ver siguiente subsección) que demuestran empíricamente poder generar intervalos de predicción que continene a la predicción verdadera (es decir, la demostración es empírica, no matemática). Y un artículo muy reciente ha demostrado que ni siquiera se necesita asumir intercambiabilidad, aunque el coste computacional de este método es algo: [\"_Conformal Validity Guarantees Exist for Any Data Distribution (and How to Find Them)\"_](https://arxiv.org/abs/2405.06627). A continuación aplicamos la \"Inductive Conformal Prediction\" o \"Split Conformal Prediction\" que no requiere reentrenar el modelo de aprendizaje automático para cada inferencia, en contraposición de la \"Transductive Conformal Prediction\", la CP original, que implica reentrenar en cada predicción.\n",
    "\n",
    "Así, la 'Conformal Prediction' nos cuantifica la incertidumbre en forma de intervalos de predicción, también llamados 'conformal intervals' (para tareas de clasificación, 'conformal sets'), que con garantía estadística incluyen la prediccion correcta con cierta probabilidad, lo cual se llama 'coverage guarantee'. Entonces, en lugar de obtener predicciones puntuales ('single-point predictions'), es decir, un número real en el caso de una regresión o la etiqueta de una clase (recordemos el último ejemplo en `Exploration_and_classification.ipynb` donde la nueva paciente obtenia una 'raw score' de 0.32, con el umbral de decisión en 't = 0.4', nos clasificaba a esa paciente con una única clase 'HeartDisease = 0') en el caso de una clasificación, los resultados calibrados con 'Conformal prediction' nos dan un intervalo de números reales o un conjunto de etiquetas, respectivamente.\n",
    "    \n",
    "Por ejemplo, aplicando 'Conformal Prediction' a los resultados de un modelo de aprendizaje automático (una Deep Neural Network en PyTorch) para una clasificación de imágenes, vemos que éste:\n",
    "    \n",
    "+ no está muy seguro de si la primera foto era un osciloscopio, así que nos lo ofrece como primera opción en un interval set con otras dos opciones, 'microondas' y 'portátil', \n",
    "+ tampoco está muy seguro de la foto central, de nuevo nos dió la respuesta correcta como primera opción pero el interval set contiene también 'refrigerador' y ' lavadora', y\n",
    "+ está muy seguro de que en la foto de la derecha hay une perre de raza 'Irish Setter' (seguro que ha visto muchos como ese, para el modelo no es para nada una imagen rara), y es la única opción del interval set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910d84b",
   "metadata": {},
   "source": [
    "![CP_example](./images/CP_4.png \"CP_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36d8e43",
   "metadata": {},
   "source": [
    "[Fuente de la imagen: Google Colab de A. Angelopoulos desarrollador de MAPIE](https://colab.research.google.com/github/aangelopoulos/conformal_classification/blob/master/example.ipynb#scrollTo=oIiBD-pFVdkD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49acbc82",
   "metadata": {},
   "source": [
    "Recordamos que el intervalo de predicción que obtenemos con la 'Conformal Prediccion' no es un mero ranking de las 'raw scores' de cada clase si no una verdadera probabilidad con garantías estadísticas de que la verdadera clase está dentro de ese intervalo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f54a4",
   "metadata": {},
   "source": [
    "<font color=#6B8E23 size=\"4\"> Material adicional y referencias</font>\n",
    "\n",
    "<font color=#6B8E23 size=\"3\"> Cursos, charlas, y blogs\n",
    "\n",
    "+ Las slides de mi charla [\"Conformal Prediction: Key Concepts\"](https://docs.google.com/presentation/d/1bQYIFyQysQPx79wJq1mltylsH_aeO2AnLYRlHiLq6vo/edit#slide=id.g2dd387acb29_0_4)\n",
    "    \n",
    "+ El curso gratuito de Christoph Molnar (subscríbete [aquí](https://substack.com/sign-in?redirect=%2Faccount%3Futm_source%3Dsubstack%26utm_medium%3Demail&for_pub=mindfulmodeler&email=&with_password=&change_user=false&justTrying=)), el autor del maravilloso libro gratuito sobre XAI [_\"Interpretable Machine Learning\"_](https://christophm.github.io/interpretable-ml-book/), que recomendamos en el Jupyter Notebook `XAI.ipynb`, que ahora se ha pasado a la UQ y ha publicado un libro sobre Conformal Prediction [_\"Introduction To Conformal Prediction With Python. A Short Guide For Quantifying Uncertainty Of Machine Learning Models\"_](https://christophmolnar.com/books/conformal-prediction/) <font size=\"3\">♫♫🎈♫♫</font>.\n",
    "+ El genial post sobre cómo usan Conformal Prediction para conformalizar la clasificación de sus clientes en el [banco BBVA](https://www.bbvaaifactory.com/es/conformal-prediction-an-introduction-to-measuring-uncertainty/)\n",
    "+ La maravillosa charla _\"Quantifying uncertainty in Machine Learning predictions\"_ de [Maria Navarro](https://youtu.be/r6bhm_A-YcQ).\n",
    "+ La charla sobre Conformal Predictors en el [curso sobre incertidumbre de la Universidad de Pennsylvania](https://uncertaintyclass.com/), este es el [vídeo](https://youtu.be/M3tkM4dcIPA).\n",
    "+ El blog de los creadores de los 'Conformal Predictors'  [Prof. Vladimir Vovk y Prof. Alex Gammerman](https://cml.rhul.ac.uk/cp.html).\n",
    "+ Este [kernel de Kaggle](https://www.kaggle.com/code/carlmcbrideellis/regression-prediction-intervals-with-mapie) que explica como usar los Conformal Predictors en una tarea de regresión.\n",
    "+ El repositorio ['Awesome Conformal Prediction'](https://github.com/valeman/awesome-conformal-prediction) y los artículos de Medium de Valeriy Manokhin del grupo de investigación que creó la 'Conformal Prediction'.\n",
    "    \n",
    "<font color=#6B8E23 size=\"3\"> Libros\n",
    "\n",
    "+ De nuevo el libro de Christoph Molnar [_\"Introduction To Conformal Prediction With Python. A Short Guide For Quantifying Uncertainty Of Machine Learning Models\"_](https://christophmolnar.com/books/conformal-prediction/).    \n",
    "+ El nuevo libro de Valeriy Manokhin [_\"Practical Guide to Applied Conformal Prediction in Python: Learn and apply the best uncertainty frameworks to your industry applications \"_](https://www.packtpub.com/product/practical-guide-to-applied-conformal-prediction-in-python/9781805122760).\n",
    "\n",
    "<font color=#6B8E23 size=\"3\">Librerías especializadas en Conformal Prediction</font>\n",
    "\n",
    "+ Los paquetes de Python, compatibles con Scikit-learn, que incluyen buenos tutoriales y que se pueden instalar fácilmente con `pip install`:\n",
    "    + [MAPIE](https://github.com/scikit-learn-contrib/MAPIE),\n",
    "    + [CREPES](https://github.com/henrikbostrom/crepes), incluye una implementación de CP llamada \"Conformal Predictive Systems\" que produce la cumulative distribution function de cada predición.\n",
    "    + [R2CCP](https://github.com/EtashGuha/R2CCP), especializada en regresión, calcula la incertidumbre incluso si los datos no están siempre igual de esparcidos (heterocedasticidad) o su distribución es bimodal,\n",
    "    + [PUNCC](https://github.com/deel-ai/puncc),\n",
    "    + [TorchCP](https://github.com/ml-stat-Sustech/TorchCP) especialmente para Deep Learning, \n",
    "    + [Conformal Tights](https://pypi.org/project/conformal-tights/) especializada en problemas de regresión, y\n",
    "    + [nonconformist](https://github.com/donlnz/nonconformist/blob/master/README.ipynb), el primero que hubo, incluye una implementación de la \"Transductive Conformal Prediction\".\n",
    "    \n",
    "+ Teoría y ejemplos en el repositorio [A. Angelopoulos](https://github.com/aangelopoulos/conformal-prediction), uno de los dos autores de [_\"A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification_\"](https://arxiv.org/abs/2107.07511).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601e051d",
   "metadata": {},
   "source": [
    "### Intervalos de predicción de fallo cardíaco\n",
    "\n",
    "Apliquemos la 'Conformal Prediction' a las predicciones de nuestro bosque aleatorio. \n",
    "\n",
    "Como estamos ante una tarea de clasificación binaria, usamos el método denominado 'Inductive Venn-ABERS Prediction (IVAP)' descrita en el artículo [_\"Large-scale probabilistic prediction with and without validity guarantees\"_](http://alrw.net/articles/13.pdf).\n",
    "\n",
    "Este método, al ser \"Inductive\" requiere de un conjunto de datos de calibración que ya separamos al comienzo del este Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f17fac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation CALIBRATION data\n",
    "\n",
    "# reset index after the splitting shuffling\n",
    "df_cal = df_cal.reset_index(drop=True)\n",
    "# define target of the test set\n",
    "y_cal = df_cal.HeartDisease.values\n",
    "   \n",
    "# 1. encode the categorical features and remove redundant columns-------------    \n",
    "\n",
    "cal_dict = df_cal[categorical].to_dict(orient='records')\n",
    "X_cal_cat = dv.transform(cal_dict) \n",
    "\n",
    "# convert the data array to a dataframe\n",
    "df_X_cal_cat = pd.DataFrame(X_cal_cat,columns= dv.get_feature_names_out())\n",
    "\n",
    "# remove redundant columns\n",
    "df_X_cal_cat.drop(['ExerciseAngina=N', 'FastingBS=H', 'Sex=F', 'ST_Slope=Up'], \n",
    "                    axis=1, inplace=True)\n",
    "\n",
    "# convert the dataframe to a np.array again\n",
    "X_cal_cat = df_X_cal_cat.to_numpy()\n",
    "\n",
    "# 2. scale the numerical features --------------------------------------------\n",
    "\n",
    "X_cal_num = df_cal[numerical].values\n",
    "#X_cal_num = scaler.transform(X_cal_num) \n",
    "\n",
    "# 3. join the matrices -------------------------------------------------------\n",
    "\n",
    "X_cal = np.column_stack([X_cal_num, X_cal_cat]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb13eb",
   "metadata": {},
   "source": [
    "Usamos la implementación del repositorio de [Paolo Toccaceli](https://github.com/ptocca/VennABERS/), que para cada paciente nos calculará los límites superior e inferior de los intervalos de predicción y la probabilidad conformalizada. Simplemente copiamos y pegamos aquí el código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc61accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some elementary functions to speak the same language as the paper\n",
    "# (at some point we'll just replace the occurrence of the calls with the function body itself)\n",
    "def push(x,stack):\n",
    "    stack.append(x)\n",
    "    \n",
    "def pop(stack):\n",
    "    return stack.pop()\n",
    "\n",
    "def top(stack):\n",
    "    return stack[-1]\n",
    "\n",
    "def nextToTop(stack):\n",
    "    return stack[-2]\n",
    "\n",
    "# perhaps inefficient but clear implementation\n",
    "def nonleftTurn(a,b,c):   \n",
    "    d1 = b-a\n",
    "    d2 = c-b\n",
    "    return np.cross(d1,d2)<=0\n",
    "\n",
    "def nonrightTurn(a,b,c):   \n",
    "    d1 = b-a\n",
    "    d2 = c-b\n",
    "    return np.cross(d1,d2)>=0\n",
    "\n",
    "def slope(a,b):\n",
    "    ax,ay = a\n",
    "    bx,by = b\n",
    "    return (by-ay)/(bx-ax)\n",
    "\n",
    "def notBelow(t,p1,p2):\n",
    "    p1x,p1y = p1\n",
    "    p2x,p2y = p2\n",
    "    tx,ty = t\n",
    "    m = (p2y-p1y)/(p2x-p1x)\n",
    "    b = (p2x*p1y - p1x*p2y)/(p2x-p1x)\n",
    "    return (ty >= tx*m+b)\n",
    "\n",
    "kPrime = None\n",
    "\n",
    "# Because we cannot have negative indices in Python (they have another meaning), I use a dictionary\n",
    "\n",
    "def algorithm1(P):\n",
    "    global kPrime\n",
    "    \n",
    "    S = []\n",
    "    P[-1] = np.array((-1,-1))\n",
    "    push(P[-1],S)\n",
    "    push(P[0],S)\n",
    "    for i in range(1,kPrime+1):\n",
    "        while len(S)>1 and nonleftTurn(nextToTop(S),top(S),P[i]):\n",
    "            pop(S)\n",
    "        push(P[i],S)\n",
    "    return S\n",
    "\n",
    "def algorithm2(P,S):\n",
    "    global kPrime\n",
    "    \n",
    "    Sprime = S[::-1]     # reverse the stack\n",
    "\n",
    "    F1 = np.zeros((kPrime+1,))\n",
    "    for i in range(1,kPrime+1):\n",
    "        F1[i] = slope(top(Sprime),nextToTop(Sprime))\n",
    "        P[i-1] = P[i-2]+P[i]-P[i-1]\n",
    "        if notBelow(P[i-1],top(Sprime),nextToTop(Sprime)):\n",
    "            continue\n",
    "        pop(Sprime)\n",
    "        while len(Sprime)>1 and nonleftTurn(P[i-1],top(Sprime),nextToTop(Sprime)):\n",
    "            pop(Sprime)\n",
    "        push(P[i-1],Sprime)\n",
    "    return F1\n",
    "\n",
    "def algorithm3(P):\n",
    "    global kPrime\n",
    "\n",
    "    S = []\n",
    "    push(P[kPrime+1],S)\n",
    "    push(P[kPrime],S)\n",
    "    for i in range(kPrime-1,0-1,-1):  # k'-1,k'-2,...,0\n",
    "        while len(S)>1 and nonrightTurn(nextToTop(S),top(S),P[i]):\n",
    "            pop(S)\n",
    "        push(P[i],S)\n",
    "    return S\n",
    "\n",
    "def algorithm4(P,S):\n",
    "    global kPrime\n",
    "    \n",
    "    Sprime = S[::-1]     # reverse the stack\n",
    "    \n",
    "    F0 = np.zeros((kPrime+1,))\n",
    "    for i in range(kPrime,1-1,-1):   # k',k'-1,...,1\n",
    "        F0[i] = slope(top(Sprime),nextToTop(Sprime))\n",
    "        P[i] = P[i-1]+P[i+1]-P[i]\n",
    "        if notBelow(P[i],top(Sprime),nextToTop(Sprime)):\n",
    "            continue\n",
    "        pop(Sprime)\n",
    "        while len(Sprime)>1 and nonrightTurn(P[i],top(Sprime),nextToTop(Sprime)):\n",
    "            pop(Sprime)\n",
    "        push(P[i],Sprime)\n",
    "    return F0\n",
    "\n",
    "def prepareData(calibrPoints):\n",
    "    global kPrime\n",
    "    \n",
    "    ptsSorted = sorted(calibrPoints)\n",
    "    \n",
    "    xs = np.fromiter((p[0] for p in ptsSorted),float)\n",
    "    ys = np.fromiter((p[1] for p in ptsSorted),float)\n",
    "    ptsUnique,ptsIndex,ptsInverse,ptsCounts = np.unique(xs, \n",
    "                                                        return_index=True,\n",
    "                                                        return_counts=True,\n",
    "                                                        return_inverse=True)\n",
    "    a = np.zeros(ptsUnique.shape)\n",
    "    np.add.at(a,ptsInverse,ys)\n",
    "    # now a contains the sums of ys for each unique value of the objects\n",
    "    \n",
    "    w = ptsCounts\n",
    "    yPrime = a/w\n",
    "    yCsd = np.cumsum(w*yPrime)   # Might as well do just np.cumsum(a)\n",
    "    xPrime = np.cumsum(w)\n",
    "    kPrime = len(xPrime)\n",
    "    \n",
    "    return yPrime,yCsd,xPrime,ptsUnique\n",
    "\n",
    "def computeF(xPrime,yCsd):\n",
    "    global kPrime\n",
    "    P = {0:np.array((0,0))}\n",
    "    P.update({i+1:np.array((k,v)) for i,(k,v) in enumerate(zip(xPrime,yCsd))})\n",
    "    \n",
    "    S = algorithm1(P)\n",
    "    F1 = algorithm2(P,S)\n",
    "    \n",
    "    P = {0:np.array((0,0))}\n",
    "    P.update({i+1:np.array((k,v)) for i,(k,v) in enumerate(zip(xPrime,yCsd))})    \n",
    "    P[kPrime+1] = P[kPrime] + np.array((1.0,0.0))    # The paper says (1,1)\n",
    "    \n",
    "    S = algorithm3(P)\n",
    "    F0 = algorithm4(P,S)\n",
    "    \n",
    "    return F0,F1\n",
    "\n",
    "def getFVal(F0,F1,ptsUnique,testObjects):\n",
    "    pos0 = np.searchsorted(ptsUnique,testObjects,side='left')\n",
    "    pos1 = np.searchsorted(ptsUnique[:-1],testObjects,side='right')+1\n",
    "    return F0[pos0],F1[pos1]\n",
    "\n",
    "def ScoresToMultiProbs(calibrPoints,testObjects):\n",
    "    # sort the points, transform into unique objects, with weights and updated values\n",
    "    yPrime,yCsd,xPrime,ptsUnique = prepareData(calibrPoints)\n",
    "    \n",
    "    # compute the F0 and F1 functions from the CSD\n",
    "    F0,F1 = computeF(xPrime,yCsd)\n",
    "    \n",
    "    # compute the values for the given test objects\n",
    "    p0,p1 = getFVal(F0,F1,ptsUnique,testObjects)\n",
    "                    \n",
    "    return p0,p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2aef3",
   "metadata": {},
   "source": [
    "Aplicando la función `ScoresToMultiProbs()` a  la lista de pares '(raw_score, target value)' de las predicciones del bosque aleatorio que obtuvimos sobre el conjunto de entrenamiento, y la 'raw score' de la instancia dada, en nuestro caso, une paciente, obtenemos el límite inferior 'p0' y superior 'p1' (i.e., los límites de nuestro intervalos de predicción) de la probabilidad bien calibrada para la clase '1', en nuestro caso la probabilidad de pertenecer al grupo en riesgo de sufrir fallo cardíaco. La probabilidad calibrada de 'HeartDisease=1' para esa paciente se calcula con la fórmula `p_calibrada = p1/(1 - p0 + p1)` que se obtiene a partir de los límites de nuestro intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e218c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model application on TRAINIG data to get the 'raw scores'\n",
    "y_pred_train = RF.predict_proba(X_proper_train)[:, 1]\n",
    "# model application on CALIBRATION data for calibration\n",
    "y_pred_cal = RF.predict_proba(X_cal)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce49b21",
   "metadata": {},
   "source": [
    "Apliquemos el análisis sobre algunes pacientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aa99e1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Raw score' for the prediction risk of heart disease 0.86\n",
      "Actual risk of heart disease:     1\n",
      "Calibrated score is: 0.96\n",
      "Probability of suffering heart failure is 96.0 %\n",
      "Prediction interval: [ 0.96 , 0.97 ]\n",
      "Lenght 0.01\n"
     ]
    }
   ],
   "source": [
    "patient_number = 0 \n",
    "individual_prediction_array = X_test[patient_number : (patient_number + 1)]\n",
    "#df_X_test.iloc[patient_number].values.reshape(1, -1)\n",
    "y_pred_test = RF.predict_proba(individual_prediction_array)[0][1].round(2)\n",
    "print(\"'Raw score' for the prediction risk of heart disease\", y_pred_test)\n",
    "print(\"Actual risk of heart disease:    \", y_test[patient_number])\n",
    "\n",
    "# apply Conformal Prediction\n",
    "p0,p1 = ScoresToMultiProbs(list(zip(y_pred_train,y_proper_train)),y_pred_test)\n",
    "# p0 and p1 are both probabilities of class 1 (lower and upper bound)\n",
    "# the difference tells us how hard it is to classify this instance\n",
    "\n",
    "print('Calibrated score is:', (p1/(1 - p0 + p1)).round(2))\n",
    "print('Probability of suffering heart failure is', (((p1/(1 - p0 + p1)).round(2))*100).round(0),'%')\n",
    "print('Prediction interval: [', p0.round(2),',', p1.round(2),']')\n",
    "print('Lenght', (p1 - p0).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24109d3",
   "metadata": {},
   "source": [
    "Vemos que es une paciente bien clasificade como fuera de riesgo cuyo intervalo de predicción es menor de 0.05, con una confianza del 95% aceptaríamos esta predicción como confiable. Al calibrar, la probabilidad de fallo cardíaco es aún menor que la puntuación predicha por el modelo sin calibrar. \n",
    "\n",
    "Probemos otre paciente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88ffb024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Raw score' for the prediction risk of heart disease 0.97\n",
      "Actual risk of heart disease:     1\n",
      "Calibrated score is: 0.98\n",
      "Probability of suffering heart failure is 98.0 %\n",
      "Prediction interval: [ 0.98 , 1.0 ]\n",
      "Lenght 0.02\n"
     ]
    }
   ],
   "source": [
    "patient_number = 1 \n",
    "individual_prediction_array = X_test[patient_number : (patient_number + 1)]\n",
    "#df_X_test.iloc[patient_number].values.reshape(1, -1)\n",
    "y_pred_test = RF.predict_proba(individual_prediction_array)[0][1].round(2)\n",
    "print(\"'Raw score' for the prediction risk of heart disease\", y_pred_test)\n",
    "print(\"Actual risk of heart disease:    \", y_test[patient_number])\n",
    "\n",
    "# apply Conformal Prediction\n",
    "p0,p1 = ScoresToMultiProbs(list(zip(y_pred_train,y_proper_train)),y_pred_test)\n",
    "# p0 and p1 are both probabilities of class 1 (lower and upper bound)\n",
    "# the difference tells us how hard it is to classify this instance\n",
    "\n",
    "print('Calibrated score is:', (p1/(1 - p0 + p1)).round(2))\n",
    "print('Probability of suffering heart failure is', (((p1/(1 - p0 + p1)).round(2))*100).round(0),'%')\n",
    "print('Prediction interval: [', p0.round(2),',', p1.round(2),']')\n",
    "print('Lenght', (p1 - p0).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b358d",
   "metadata": {},
   "source": [
    "Este es une paciente también clasificade correctamente, esta vez como en riesgo de fallo. Su intervalo es menor que 0.05, podemos confiar en el resultado, y vemos que la puntuación cruda no estaba muy lejos de la correspondiente probabilidad.  \n",
    "\n",
    "Veamos otre paciente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9213761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Raw score' for the prediction risk of heart disease: 0.68\n",
      "Actual risk of heart disease: 1\n",
      "Calibrated score is: 0.87\n",
      "Probability of suffering heart failure is 87.0 %\n",
      "Prediction interval: [ 0.86 , 0.97 ]\n",
      "Lenght 0.12\n"
     ]
    }
   ],
   "source": [
    "patient_number = 2  #16  \n",
    "\n",
    "# predict\n",
    "individual_prediction_array = X_test[patient_number : (patient_number + 1)]\n",
    "#df_X_test.iloc[patient_number].values.reshape(1, -1)\n",
    "y_pred_test = RF.predict_proba(individual_prediction_array)[0][1].round(2)\n",
    "print(\"'Raw score' for the prediction risk of heart disease:\", y_pred_test)\n",
    "print(\"Actual risk of heart disease:\", y_test[patient_number])\n",
    "\n",
    "# apply Conformal Prediction\n",
    "p0,p1 = ScoresToMultiProbs(list(zip(y_pred_train,y_proper_train)),y_pred_test)\n",
    "# p0 and p1 are both probabilities of class 1 (lower and upper bound)\n",
    "# the difference tells us how hard it is to classify this instance\n",
    "print('Calibrated score is:', (p1/(1 - p0 + p1)).round(2))\n",
    "print('Probability of suffering heart failure is', (((p1/(1 - p0 + p1)).round(2))*100).round(0),'%')\n",
    "print('Prediction interval: [', p0.round(2),',', p1.round(2),']')\n",
    "print('Lenght', (p1 - p0).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1f831",
   "metadata": {},
   "source": [
    "Este es une paciente con fallo cardíaco que el bosque aleatorio clasificó correctamente pero vemos que su puntuación calibrada es mayor que lo que predecía la puntuación cruda y que su intervalo de predicción mide más de 0.05, esta predicción no sería confiable. Algo parecido ocurre con le `patient_number = 16`, cuya predicción es aún menos confiable, por si quieres editar la celda anterior para probarlo. \n",
    "\n",
    "Veamos qué ocurre con les paciente que son Falsos Negativos, aquellos resultados que intentamos evitar por ser el error más costoso en medicina, son el `patient_number = 4` y el `patient_number = 24`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fe1cb6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Raw score' for the prediction risk of heart disease 0.33\n",
      "Actual risk of heart disease:     1\n",
      "Calibrated score is: 0.14\n",
      "Probability of suffering heart failure is 14.0 %\n",
      "Prediction interval: [ 0.09 , 0.15 ]\n",
      "Lenght 0.07\n"
     ]
    }
   ],
   "source": [
    "patient_number = 4 #24\n",
    "individual_prediction_array = X_test[patient_number : (patient_number + 1)]\n",
    "#df_X_test.iloc[patient_number].values.reshape(1, -1)\n",
    "y_pred_test = RF.predict_proba(individual_prediction_array)[0][1].round(2)\n",
    "print(\"'Raw score' for the prediction risk of heart disease\", y_pred_test)\n",
    "print(\"Actual risk of heart disease:    \", y_test[patient_number])\n",
    "\n",
    "# apply Conformal Prediction\n",
    "p0,p1 = ScoresToMultiProbs(list(zip(y_pred_train,y_proper_train)),y_pred_test)\n",
    "# p0 and p1 are both probabilities of class 1 (lower and upper bound)\n",
    "# the difference tells us how hard it is to classify this instance\n",
    "\n",
    "print('Calibrated score is:', (p1/(1 - p0 + p1)).round(2))\n",
    "print('Probability of suffering heart failure is', (((p1/(1 - p0 + p1)).round(2))*100).round(0),'%')\n",
    "print('Prediction interval: [', p0.round(2),',', p1.round(2),']')\n",
    "print('Lenght', (p1 - p0).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133175f",
   "metadata": {},
   "source": [
    "Vemos que la Prediccion Conforme en este caso no consigue reclasificar correctamente los 2 Falsos Negativos pero nos ofrece intervalos de predicción mayores que el riesgo acceptado. Con la anchura de 0.07, al ser mayor de 0.05, nos indica que no debemos confiar en estas predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4adfd",
   "metadata": {},
   "source": [
    "Pero veamos qué ocurre con los Falsos Positivos, les 2 pacientes sin fallo cardíaco que el bosque aleatorio clasificó incorrectamente. Son `patient_number = 6` y `patient_number = 12`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3ba8289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Raw score' for the prediction risk of heart disease 0.9\n",
      "Actual risk of heart disease:     0\n",
      "Calibrated score is: 0.97\n",
      "Probability of suffering heart failure is 97.0 %\n",
      "Prediction interval: [ 0.97 , 1.0 ]\n",
      "Lenght 0.03\n"
     ]
    }
   ],
   "source": [
    "patient_number = 6 #12\n",
    "individual_prediction_array = X_test[patient_number : (patient_number + 1)]\n",
    "#df_X_test.iloc[patient_number].values.reshape(1, -1)\n",
    "y_pred_test = RF.predict_proba(individual_prediction_array)[0][1].round(2)\n",
    "print(\"'Raw score' for the prediction risk of heart disease\", y_pred_test)\n",
    "print(\"Actual risk of heart disease:    \", y_test[patient_number])\n",
    "\n",
    "# apply Conformal Prediction\n",
    "p0,p1 = ScoresToMultiProbs(list(zip(y_pred_train,y_proper_train)),y_pred_test)\n",
    "# p0 and p1 are both probabilities of class 1 (lower and upper bound)\n",
    "# the difference tells us how hard it is to classify this instance\n",
    "\n",
    "print('Calibrated score is:', (p1/(1 - p0 + p1)).round(2))\n",
    "print('Probability of suffering heart failure is', (((p1/(1 - p0 + p1)).round(2))*100).round(0),'%')\n",
    "print('Prediction interval: [', p0.round(2),',', p1.round(2),']')\n",
    "print('Lenght', (p1 - p0).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af94cc5",
   "metadata": {},
   "source": [
    "Por desgracia ambos Falsos Positivos tienen un intervalo de predicción es muy estrechito, la confomalización indica erróneamente que es un resultado confiable. La Predicción Conforme sobre el Bosque Aleatorio no ha sido lo suficientemente potente para identificar lo inusual de estos resultado y los clasifica como confiables a pesar de ser erróneos. Solo un nivel de confianza del 99% habría detectado estos casos. Cómo siempre, aumentar el tamaño de los conjuntos de entrenamiento y calibración también puede que mejorara los resultados, no tanto por la parte de la conformalización sino porque aumentaría el rendimiento del Bosque Aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a250f",
   "metadata": {},
   "source": [
    "Veamos los resultados conformes para todo el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4cc46d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model application on TEST data\n",
    "y_pred_test = RF.predict_proba(X_test)[:, 1]\n",
    "p_pars = []\n",
    "intervals_len = [] \n",
    "conform_proba = []\n",
    "\n",
    "\n",
    "for i in y_pred_test:\n",
    "    p0,p1 = ScoresToMultiProbs(list(zip(y_pred_train,y_proper_train)),i)\n",
    "    p_pars.append([p0,p1])\n",
    "    intervals_len.append((p1 - p0).round(3))\n",
    "    conform_proba.append((p1/(1 - p0 + p1)).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab59a7ba",
   "metadata": {},
   "source": [
    "Las probabilidades calibradas, ya legítimas y no solo heurísticas, son las `conform_proba` y la longitud de sus intervalos de predicción correspondientes son los `intervals_len`, con sus límites inferior e inferior almacenados en `p_pars`. \n",
    "\n",
    "Vemos que varios intervalos de predicción son muy grandes, esas son las predicciones con más incerticumbre, vamos a separarlas. En un ejemplo real, implementaremos una señal y el programa nos dirá 'no puedo predecir, no tengo ni idea' y une humane se encargará de clasificar estas instancias. Separamos aquellas cuyo intervalo sea muy grande, más grandes que cierto 'nivel de confianza' $\\epsilon$, veamos cual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6fdf3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x74ffbb23be50>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(intervals_len),'-*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5291bac",
   "metadata": {},
   "source": [
    "Viendo la longitud de los intervalos, parece razonable descartar aquellos más largos que $\\epsilon$ = 0.05. Cuánto mayor este valor, más pacientes serán clasificadxs en la clase 'no tengo ni idea' y menos pacientes serán clasificadxs automáticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0b9202de",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_bool = np.array(intervals_len) < 0.05 #gives bollean True/False in the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c4ec065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "certain_predictions = np.array(conform_proba)[epsilon_bool] #takes True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "16ed87e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients in test set = 30\n",
      "Number of automatic classifications = 19\n",
      "Number of human-assisted classifications = 11\n"
     ]
    }
   ],
   "source": [
    "print('Number of patients in test set =', len(X_test))\n",
    "print('Number of automatic classifications =',len(certain_predictions))\n",
    "print('Number of human-assisted classifications =',len(X_test) - len(certain_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e312f3",
   "metadata": {},
   "source": [
    "En aplicaciones reales, puede ser preferible esa inversión en tiempo humano que asumir las clasificaciones incorrectas. Por ejemplo, en nuestro caso, une experte en medicina evaluaría a eses pacientes seleccionados gracias a la cuantifición de incertidumbre y les dirigiría a hacerse nuevas pruebas médicas, por ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa7c5c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "t = 0.4\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test[epsilon_bool], certain_predictions >= t)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Confusion Matrix\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "ax.xaxis.set_ticklabels(['0','1'])\n",
    "ax.yaxis.set_ticklabels(['0','1'])\n",
    "\n",
    "##plt.figure(figsize=(7,5))\n",
    "plt.rcParams['figure.figsize'] = [7, 5]  # re-run this cell to get the correct figure size\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9aed0a",
   "metadata": {},
   "source": [
    "Con la 'Conformal Prediction' hemos detectado las instancias con el intervalo de predicción más largo y las hemos sacado de la clasificación automática para que las evalue una persona experta. Así hemos conseguido reducido el 100% de los Falsos Negativos (ver la matriz de confusión que obtuvimos para el conjunto de prueba sin conformar en la sección <a href=#model-RF>3.2 Entrenamiento, prueba, y aplicación del bosque aleatorio</a>).\n",
    "\n",
    "<font size=\"5\"> 🥳 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c6579",
   "metadata": {},
   "source": [
    "<a name='uq-others'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927449c",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>4.2 Otros métodos de UQ para aprendizaje supervisado</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca935df3",
   "metadata": {},
   "source": [
    "La 'Conformal prediction' puede aplicarse para todo tipo de modelos de aprendizaje automático. Sin embargo, al contrario que la mayoría de los métodos de explicabilidad que mostramos en el Jupyter Notebook anterior `XAI.ipynb`, muchos métodos de UQ son específicos, por ejemplo, se aplican solo a tareas de regresión. Mencionaremos algunos muy populares y cabe mencionar que:\n",
    "\n",
    "+ todos los métodos de UQ que no usen CP se deben calibrar con 'Conformal Predictions' o estarímos en las mismas que con los 'raw scores' de `.predict_proba()`.\n",
    "\n",
    "+ solo la Conformal Prediction nos da garantía de cobertura de que el resultado contiene el valor verdadero. Por ejemplo, la primera columna de siguiente tabla del artículo [Valid prediction intervals for regression problems](https://link.springer.com/article/10.1007/s10462-022-10178-5) (en Arxiv está la [última versión](https://arxiv.org/abs/2107.00363)) dónde se revisan varios métodos de UQ para regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d833a3e",
   "metadata": {},
   "source": [
    "![Waegeman_benchmark](./images/Waegeman_UQ_benchmark.png \"Waegeman_benchmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b5f74d",
   "metadata": {},
   "source": [
    "[Fuente de la imagen: Valid prediction intervals for regression problems](https://link.springer.com/article/10.1007/s10462-022-10178-5), en Arxiv está la [última versión](https://arxiv.org/abs/2107.00363). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cad2b03",
   "metadata": {},
   "source": [
    "<font color=#ac6240>Paquetes que implementan CP y otros métodos de UQ para cualquier tarea </font>\n",
    "+ [PiML](https://selfexplainml.github.io/PiML-Toolbox/_build/html/guides/testing/reliability.html)\n",
    "+ [AWS Fortuna](https://github.com/awslabs/fortuna?tab=readme-ov-file) (para CP con time series soluciona el asunto de la intercambiabilidad implementando [EnbPI](https://proceedings.mlr.press/v139/xu21h/xu21h.pdf), como hace MAPIE)\n",
    "+ [Lightning UQ Box](https://github.com/lightning-uq-box/lightning-uq-box) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722624af",
   "metadata": {},
   "source": [
    "<font color=#ac6240>Tareas de Regresión</font>\n",
    "\n",
    "El artículo y el Jupyter Notebook del [tutorial de Martim Sousa](https://github.com/Quilograma/ConformalPredictionTutorial/tree/main) (también incluye la explicación para la Quantile Regression, ver siguiente punto aquí abajo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ce16c",
   "metadata": {},
   "source": [
    "<font color=#ac6240>Quantile Regression</font>\n",
    "\n",
    "Pertenece al grupo \"Direct Interval Estimation\" de la tabla anterior.\n",
    "\n",
    "+ Una breve y genial explicación de la [Quantile Regression escrita por Christoph Molnar](https://mindfulmodeler.substack.com/p/how-i-made-peace-with-quantile-regression) y sobre como [conformalizarla aquí](https://mindfulmodeler.substack.com/p/week-3-conformal-prediction-for-regression).\n",
    "+ Más sobre conformalizar la Quantile Regression en [_\"A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification\"_](https://arxiv.org/pdf/2107.07511.pdf) sección \"2. Examples of Conformal Procedures\" y [_\"Another (Conformal) Way to Predict Probability Distributions: Conformal multi-quantile regression with Catboost\"_](https://towardsdatascience.com/another-conformal-way-to-predict-probability-distributions-fcc63e78680d)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ab961",
   "metadata": {},
   "source": [
    "<font color=#ac6240>Ensembles</font>\n",
    "\n",
    "Suelen ser computacionalmente costosos porque implican entrenar muchas versiones de los modelos de aprendizaje automático y no ofrecen garantía de cobertura. Un ejemplo de aplicación:  [_\"Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles\"_](https://papers.nips.cc/paper/2017/hash/9ef2ed4b7fd2c810847ffa5fa85bce38-Abstract.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41554b3",
   "metadata": {},
   "source": [
    "<font color=#ac6240>Bayesianos</font>\n",
    "\n",
    "Suelen ser computacionalmente costosos porque implican predecir la distribución completa, siempre dependen de un prior que puede ser difícil de estimar y por lo tanto no ser fiable, y no garantizan la cobertura. Para que los los resultados de los métodos bayesianos cumplan \"validity\" pueden conformalizarse, ver por ejemplo:\n",
    "\n",
    "+ [Valid prediction intervals for regression problems](https://link.springer.com/article/10.1007/s10462-022-10178-5) (en Arxiv está la [última versión](https://arxiv.org/abs/2107.00363)), \n",
    "+ [Bayesian Optimization with Formal Safety Guarantees via Online Conformal Prediction](https://arxiv.org/abs/2306.17815), and \n",
    "+ [Online Calibrated and Conformal Prediction Improves Bayesian Optimization](https://proceedings.mlr.press/v238/deshpande24a/deshpande24a.pdf).\n",
    "\n",
    "Sobre métodos bayesianos en general:\n",
    "\n",
    "+ Este artículo en este blog: [El Paradigma Bayes para escenarios de incertidumbre](https://keepler.io/es/2020/03/el-paradigma-bayes-para-escenarios-de-incertidumbre/).\n",
    "\n",
    "+ La librería de Python [PyMC3](https://pypi.org/project/pymc3/) (que ahora se llama [PyMC](https://www.pymc.io/blog/v4_announcement.html)) y el repo [Probabilistic Python: An Introduction to Bayesian Modeling with PyMC](https://github.com/fonnesbeck/probabilistic_python).\n",
    "\n",
    "+ Métodos Bayesianos para clasificación y regresión como BART [Bayesian Additive Regression Trees](https://jmloyola.github.io/posts/2019/06/introduction-to-bart)\n",
    "\n",
    "+ Para 'Gaussian Processes', ver por ejemplo: [_\"Easy introduction to gaussian process regression (uncertainty models)\"_](https://youtu.be/iDzaoEwd0N0) y [_\"Coding gaussian process regressors FROM SCRATCH in python\"_](https://youtu.be/JXdrq7--XV0) con este [repo](https://gitlab.com/youtube-optimization-geeks/uncertainty-quantification/-/blob/main/coing_gpr_from_scratch_notebook.ipynb).\n",
    "\n",
    "+ Para Deep Learning, la charla _\"Are you sure about that?! Uncertainty Quantification in AI\"_ de [Florian Wilhelm](https://youtu.be/LCDIqL-8bHs) con aplicaciones en Deep Learning para tareas de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996223d",
   "metadata": {},
   "source": [
    "<font color=#ac6240>Para Time Series, donde los datos no son intercambiables</font>\n",
    "\n",
    "+ La explicación de cómo usar la libreria `MAPIE` con los Conformal Predictors para UQ en time series: [_\"Time Series Forecasting with Conformal Prediction Intervals: Scikit-Learn is All you Need\"_](https://towardsdatascience.com/time-series-forecasting-with-conformal-prediction-intervals-scikit-learn-is-all-you-need-4b68143a027a). Soluciona el asunto de la intercambiabilidad implementando [EnbPI](https://proceedings.mlr.press/v139/xu21h/xu21h.pdf), como hace AWS Fortuna.\n",
    "\n",
    "+ [NeuralProphet](https://pypi.org/project/neuralprophet/) tiene implementada la función `.conformal_predict()` para conformalizar la Quantile Regression en time series, [este Jupyter Notebook](https://github.com/ourownstory/neural_prophet/blob/main/tutorials/feature-use/uncertainty_conformal_prediction.ipynb) contiene un ejemplo prediciendo la demanda de energia de un hospital. \n",
    "\n",
    "+ [MLforecast](https://nixtlaverse.nixtla.io/mlforecast/docs/how-to-guides/prediction_intervals.html) y el modelo fundacional [TimeGPT](https://nixtlaverse.nixtla.io/nixtla/docs/tutorials/prediction_intervals.html) de Nixtla incluyen CP. Solucionan el asunto de la incercambiabilidad implementando [CFTS](https://proceedings.neurips.cc/paper_files/paper/2021/file/312f1ba2a72318edaaa995a67835fad5-Paper.pdf).\n",
    "\n",
    "+ [Sktime](https://www.sktime.net/en/stable/examples/01b_forecasting_proba.html) También solucionan el asunto de la incercambiabilidad implementando [CFTS](https://proceedings.neurips.cc/paper_files/paper/2021/file/312f1ba2a72318edaaa995a67835fad5-Paper.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82343712",
   "metadata": {},
   "source": [
    "<a name='miscelanea'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c6be6",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>4.3 Miscelánea</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b03f4",
   "metadata": {},
   "source": [
    "<font color=#ac6240>GAMLSS</font>\n",
    "\n",
    "Los Generalized Additive Models for Location, Scale and Shape son modelos de regresión que no predicen los valores de la variable de destino o 'target' sino que predicen los parametros que definen su distribución, es decir, la localización (por ejemplo, la media), la escala (por ejemplo, la varianza), y la forma (por ejemplo, la kurtosis y la 'skewness'), más info en [este artículo](https://www.cienciadedatos.net/documentos/63_gamlss.html).    \n",
    "\n",
    "La libreíra [Lightning UQ Box](https://github.com/lightning-uq-box/lightning-uq-box) implementa la \"Mean-Variance Estimation\" donde el resultado de la red neuronal es la media y la varianza de la distribución de la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c369c",
   "metadata": {},
   "source": [
    "<font color=#ac6240>UQ + XAI</font>\n",
    "\n",
    "Podemos aplicar UQ no solo a los resultados de la predicción sino a los resultados de la XAI que obtuvimos en el anterior Jupyter Notebook sobre explicabilidad en este taller y dotar de intervalos de predicción a los Shapley Values, como en este artículo: [But Are You Sure? An Uncertainty-Aware Perspective on Explainable AI](https://proceedings.mlr.press/v206/marx23a/marx23a.pdf).\n",
    "\n",
    "El 'framework' de IBM [AIF360](https://github.com/Trusted-AI/AIF360/blob/master/examples/README.md) aplica XAI para mitigar sesgos y que también recomendamos en el Jupyter Notebook `XAI.ipynb`, incluye técnicas como la clasificación con opción de rechazo o 'Reject Option-based Classification' (ROC), también llamada 'Selective Prediction', un método que asume que el modelo de aprendizaje automático asignó 'raw scores' cercanas al valor del umbral de decisión a aquellas predicciones de las que estaba menos seguro, como por ejemplo, la de le perre que parecía un poco une gate en la foto central de las imágenes de la sección <a href=#project-description-intro>1.1 Introducción</a>) y las separa en una nueva clase, es decir, los resultados posibles son '0', '1', y 'no tengo ni idea'. IBM también tiene el framework  [UQ360](https://uq360.mybluemix.net/) con muchos métodos de UQ (por desgracia no incluye CP) e incluye [tutoriales](https://uq360.mybluemix.net/resources/tutorials) y una [guía de algoritmos y métricas](https://uq360.mybluemix.net/resources/guidance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b7790",
   "metadata": {},
   "source": [
    "<font color=#ac6240>Causal Inference</font>\n",
    "\n",
    "+ Blogs como [Causal Inference for The Brave and True](https://matheusfacure.github.io/python-causality-handbook/landing-page.html) \n",
    "+ Frameworks como [Azure EconML](https://econml.azurewebsites.net/spec/causal_intro.html), [Microsoft DoWhy](https://github.com/py-why/dowhy), o [Uber CausalML](https://github.com/uber/causalml) \n",
    "+ La charla _\"Introducción a la causalidad en Python \"_ de [Albert Pujol Torras y Miguel F. Alarcón](https://charlas.2022.es.pycon.org/pycones2022/talk/FTGTLS/) en la PyConES 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f221f646",
   "metadata": {},
   "source": [
    "<font color=#ac6240>Modelos híbridos</font>\n",
    "\n",
    "Son aquellos que incluyen 'domain expertise' para comprobar que se cumplen las restricciones que tenga el sistema, (por ejemplo las leyes de conservación de la energía y la masa, limitaciones de presupuesto,...) o para 'feature engineering'; un ejemplo son las Physic Guided o [Physic Informed Neural Networks](https://en.wikipedia.org/wiki/Physics-informed_neural_networks) como en el artículo [_\"Physics-guided Neural Networks (PGNN): An Application in Lake Temperature Modeling\"_](https://arxiv.org/pdf/1710.11431.pdf) un ejemplo de una red neuronal artificial aplicada en hidrología que arrojaba soluciones que permitían que agua líquida más densa flotara sobre agua líquida menos densa. \n",
    "\n",
    "**Si es que si no se lo dices, todo esto al algoritmo le da igual**.\n",
    "\n",
    "\n",
    "<font size=\"6\">🤦🏻‍♀️</font>\n",
    "\n",
    "La librería [SciANN](https://www.sciann.com/#new-to-sciann) permite modificar la loss function de las redes neuronales para penalizar aquellas soluciones que violen las limitaciones deseadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75570e5d",
   "metadata": {},
   "source": [
    "<a href=#toc>Subir a Tabla de Contenidos</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ba322",
   "metadata": {},
   "source": [
    "<a name='uq-end'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf631676",
   "metadata": {},
   "source": [
    "### <font color=#ac6240>5. Conclusión sobre la cuantificación de incertidumbre</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bddb1",
   "metadata": {},
   "source": [
    "Con los métodos de UQ hemos conseguido:\n",
    "+ identificar la aquellos pacientes sobre cuya clasificacion el bosque aleatorio no estaba muy seguro, y \n",
    "+ reducir nuestra cantidad de Falsos Negativos y Positivos. \n",
    "\n",
    "Vemos que son métodos fáciles de implementar y rápidos, y nos proporcionan probabilidades rigurosas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc656b4",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"5\">🎈♫♫🎈🎈♫🎈♫♫♫♫🎈🎈 ♫♫♫ 🎈🎈</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50717bab",
   "metadata": {},
   "source": [
    "<a href=#toc>Subir a Tabla de Contenidos</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8010c75",
   "metadata": {},
   "source": [
    "Ya no queda tiempo para más, nos vemos en el próximo taller. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f35dd0",
   "metadata": {},
   "source": [
    "<font size=\"5\">☀️⛱️ </font> Buen trabajo y hasta pronto!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
