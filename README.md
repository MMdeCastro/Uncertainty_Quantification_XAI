Este taller complementa a la mayor√≠a de los cursos introductorios sobre aprendizaje autom√°tico (machine learning) supervisado, que a menudo se centran solamente en optimizar m√©tricas de rendimiento. Si no has realizado un curso introductorio sobre aprendizaje autom√°tico supervisado, encontrar√°s un resumen en el Jupyter Notebook llamado `Exploration_and_Classification.ipynb`.

El an√°lisis completo es una serie de 3 Jupyter Notebooks, en este orden:

+ `Exploration_and_Classification.ipynb` donde exploramos y preparamos los datos, probamos varios modelos de aprendizaje autom√°tico supervisado para clasificaci√≥n, explicamos las m√©tricas de rendimiento y el umbral de decisi√≥n, y elegimos el modelo que nos da mejor rendimiento,
+ `XAI.ipynb` donde aplicamos varios m√©todos de explicabilidad o [XAI](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence), y
+ `UQ.ipynb` donde aplicamos varios m√©todos de cuantificaci√≥n de incertidumbre o [UQ](https://en.wikipedia.org/wiki/Uncertainty_quantification).

Si prefieres solo mirar el contenido sin ejecutarlo, aqu√≠ tienes los enlaces a cada uno de los temas:

[![NBViewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/MMdeCastro/Uncertainty_Quantification_XAI/blob/main/Exploration_and_Classification.ipynb) Exploraci√≥n de los datos y selecci√≥n del modelo de aprendizaje supervisado para la Clasificaci√≥n

[![NBViewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/MMdeCastro/Uncertainty_Quantification_XAI/blob/main/XAI.ipynb) Explicabilidad

[![NBViewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/MMdeCastro/Uncertainty_Quantification_XAI/blob/main/UQ.ipynb) Incertidumbre

y el enlace a las diapositivas de la presentaci√≥n introductoria para todos los p√∫blicos ["La IA no hereda nuestros sesgos si la ense√±amos c√≥mo"](https://docs.google.com/presentation/d/1bp8rJTtZ5aAGeNwwdTdue4vGcs27QvcEeA1VbHPce9c/edit#slide=id.g211627b4636_0_101).

Como dec√≠amos, √©sta es una serie introductoria y no incluimos explicaciones exhaustivas y demostraciones matem√°ticas (hay muchas otras fuentes, ver la lista de materiales en la intro de los Jupyter Notebooks), mejor mencionaremos algunas caracter√≠sticas intuitivas sobre la explicabiliad y la cuantificaci√≥n de la incertidumbre y nos enfocaremos en su implementaci√≥n en Scikit-learn, una de las librer√≠as de [Python](https://es.wikipedia.org/wiki/Python) m√°s utilizadas en aprendizaje autom√°tico.

# Exactitud con certidumbre

Medir la calidad de las predicciones de un modelo de aprendizaje autom√°tico supervisado a trav√©s de m√©tricas de rendimiento como *accuracy* (o "exactitud" en castellano), *precision*, *recall*, *F1 score*,... no nos da la seguridad de que el modelo est√© respondiendo a la pregunta correcta, sobre todo si es un modelo no interpretable por las personas, tambi√©n llamados modelos 'black box' o caja negra. 

Un ejemplo t√≠pico son los grandes modelos de aprendizaje profunzo (deep learning) fallando al intentar identificar una vaca en la playa. Esto sucede frecuentemente porque lo que en realidad aprendi√≥ el modelo durante su entrenamiento fue a reconocer la hierba en las im√°genes del conjunto de entrenamiento (training set). Son modelos muy exactos (puede que hasta obtengamos m√°s de un 95% de *accuracy* en su validaci√≥n y testado), pero en una tarea distinta, no deseada (quer√≠amos detectar vacas, no hierba). Si solamente nos fijamos en las m√©tricas, este inesperado cambio de tarea puede pasar f√°cilmente desapercibido y aumentar el tama√±o del training set no necesariamente soluciona el problema.

Podemos cerciorarnos de que esto no nos pasa incorporando a nuestro modelo herramientas matem√°ticas (ya desarrolladas como librer√≠as de Python) que nos facilitan ir m√°s all√° de la optimizaci√≥n de las m√©tricas. Estas herramientas sirven para cualquier modelo supervisado y explican en qu√© se fij√≥ el modelo para producir sus predicciones (gracias a m√©todos de explicabilidad o [XAI](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence), como los SHAP values, LIME,...) o proveen de 'barras de error' a las predicciones puntuales (utilizando m√©todos de cuantificaci√≥n de incertidumbre o [UQ](https://en.wikipedia.org/wiki/Uncertainty_quantification), como los Conformal Predictors, la Quantile Regression,..).

<font size="10"> üëçü§ì </font>

## Instrucciones

0. Clona este repositorio en el ordenador o nube donde vayas a trabajar. Si no tienes el paquete `git` instalado, [aqu√≠](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) explica c√≥mo hacerlo. Para clonar el repositorio, pincha en el bot√≥n verde que dice 'Code', copia al portapapeles la direcci√≥n htpps, y p√©gala en una terminal donde vayas a trabajar, escribiendo `git clone`, un espacio, y la direcci√≥n htpps de este repositorio, tardar√° unos segundos en descargarse.  

1. Si no tienes el administrador de paquetes `conda` instalado, puedes simplemente instalar `miniconda` siguiendo las instrucciones para tu sistema operativo [aqu√≠](https://docs.conda.io/en/latest/miniconda.html). Despu√©s, abre una terminal (de Bash si est√°s en Linux o Mac, Anaconda prompt si est√°s en Windows) y escribe:

+ `conda env create -f environment.yml`

2. Activa el entorno escribiendo en la terminal:

+ `conda activate intro_UQ_XAI`

  La primera vez tardar√° bastante, dependiendo de tu ancho de banda, puede que hasta una hora, porfa, tr√°elo ya hecho cuando vengas al taller. Cuando acabes con este proyecto, desactiva el entorno escribiendo en la terminal:

+ `conda deactivate`

3. Con el entorno activo, abre la aplicaci√≥n para editar y ejecutar el c√≥digo en Jupyter Notebooks escribiendo en la terminal:

+ `jupyter notebook`

4. Jupyter se abrir√° en tu browser. En la barra de herramientas, pincha en 'Nbextensions' y permite 'Collapsible Headings' para mejorar la lectura, son Jupyter Notebooks f√°ciles pero un poco largos! Abre el Jupyter Notebook clicando en un fichero con extensi√≥n .ipynb y sigue las instrucciones escritas all√≠. Aconsejamos empezar por `Exploration_and_Classification.ipynb`. 

<font size="10"> üìù </font>Este taller se realiz√≥ por primera vez en la [PyConES22](https://2022.es.pycon.org/) viernes 30 de Septiembre de 2022 de 15:30h a 17:30h. En el taller de la PyConES22 damos este Jupyter Notebook por sabido y empezamos directamente con `XAI.ipynb`. Todas las charlas de la PyConES 2022 que se mencionan como material complementario en los Jupyter Notebooks pueden encontrarse en [la lista de reproduci√≥n del canal de youtube de Python Espana](https://www.youtube.com/@PythonES). 
