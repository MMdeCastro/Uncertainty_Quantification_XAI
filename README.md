## M√°s all√° de la m√©trica

Este taller complementa a la mayor√≠a de los cursos introductorios sobre aprendizaje autom√°tico (machine learning) supervisado, que a menudo se centran solamente en optimizar m√©tricas de rendimiento. Si no has realizado un curso introductorio sobre aprendizaje autom√°tico supervisado, encontrar√°s un resumen en el Jupyter Notebook llamado `Exploration_and_Classification.ipynb`.

El an√°lisis completo es una serie de 4 Jupyter Notebooks, que aunque son independientes, mejor trabajarlos en este orden:

+ `Exploration_and_Classification.ipynb` donde exploramos y preparamos los datos, probamos varios modelos de aprendizaje autom√°tico supervisado para clasificaci√≥n, explicamos las m√©tricas de rendimiento y el umbral de decisi√≥n, y elegimos el modelo que nos da mejor rendimiento,
+ `XAI.ipynb` donde explicamos m√©todos de explicabilidad o [XAI](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence), y
+ `UQ.ipynb` donde explicamos m√©todos de cuantificaci√≥n de incertidumbre o [UQ](https://en.wikipedia.org/wiki/Uncertainty_quantification).

Para profundizar en la aplicaci√≥n de la UQ, ver el cuarto Jupyter Notebook `UQ_multiclass.ipynb` donde se incluye el c√≥digo para la explicaci√≥n de este [mini curso de Christoph Molnar](https://mindfulmodeler.substack.com/p/week-1-getting-started-with-conformal).

Si prefieres solo mirar el contenido sin ejecutarlo, aqu√≠ tienes los enlaces a cada uno de los temas:

[![NBViewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/MMdeCastro/Uncertainty_Quantification_XAI/blob/main/Exploration_and_Classification.ipynb) Exploraci√≥n de los datos y selecci√≥n del modelo de aprendizaje supervisado para la Clasificaci√≥n.

[![NBViewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/MMdeCastro/Uncertainty_Quantification_XAI/blob/main/XAI.ipynb) Herramientas de Explicabilidad (XAI).

[![NBViewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/MMdeCastro/Uncertainty_Quantification_XAI/blob/main/UQ.ipynb) Herramientas de Cuantificaci√≥n de Incertidumbre (UQ) y aplicaci√≥n de la Conformal Prediction para una clasificaci√≥n binaria.

[![NBViewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.org/github/MMdeCastro/Uncertainty_Quantification_XAI/blob/main/UQ_multiclass.ipynb) Conformal Predictors (CP) para la UQ en ejemplo de clasificaci√≥n multiclase.

Aqu√≠ el enlace a las diapositivas de las presentaciones introductorias (contienen animaciones, mejor verlas en modo presentaci√≥n):
+ Python Asturias ["Python para una IA Confiable"](https://docs.google.com/presentation/d/1FCUoBORSBP7cE0LYmVVQr6daqhCQ_ZJ5CPFltuPZlsQ/edit#slide=id.g2988a3002ed_0_0), y aqu√≠ est√° [el v√≠deo](https://youtu.be/sPCQVVFBuQc?si=jh3lhjFl9ZEb0fu3).
+ PyConES 2024 ["Predicci√≥n Conforme: el fin de la predicci√≥n puntual descalibrada"](https://pretalx.com/pycones-2024/talk/HSWECW/), en la descripci√≥n est√° el enlace a la presentaci√≥n,
+ CITIC - UGR ["Accuracy with Certainty: beyond the performance metrics"](https://docs.google.com/presentation/d/1pXtkpzjTj94vxgBhRlsuSFIwFkx8v53u8ZP_9lZDyi4/edit?usp=sharing),
+ DyploFest24 ["Exactitud con Certidumbre"](https://docs.google.com/presentation/d/1f2LiOLh_IQfKqGiJ1X8OIee0wxKJQZiKft5riam9UA8/edit#slide=id.g2de3d8b8587_0_17),
+ para el alumnado del M√°ster en Ciencia de Datos de la Universidad de Granada ["Introducci√≥n a la Cuantificaci√≥n de Incertidumbre en Aprendizaje Autom√°tico con Conformal Prediction"](https://docs.google.com/presentation/d/1yFHn4_Byt6_f5arFOdhUWBXOrN7BrYbmEc2gMhJ0RVY/edit?usp=sharing),
+ II Jornadas de Ciencia y G√©nero del IFIC y la Univ. de Valencia, charla para todos los p√∫blicos ["La IA no hereda nuestros sesgos si le ense√±amos c√≥mo"](https://docs.google.com/presentation/d/1bp8rJTtZ5aAGeNwwdTdue4vGcs27QvcEeA1VbHPce9c/edit#slide=id.g211627b4636_0_101). [Aqu√≠ est√° el v√≠deo](https://youtu.be/89G74PBnoVc) de la presentaci√≥n,
+ para estudiantes de inform√°tica y telecomunicaciones del Google Developer Student Club de la Univ. de Granada ["Herramientas para la explicabilidad y la cuantificaci√≥n de incertidumbre contra los sesgos del aprendizaje autom√°tico"](https://docs.google.com/presentation/d/1p5QVf4JaDDFl7IM6XLclfWbcU0a5a8Il9MTu8-9fB84/edit#slide=id.g20f7f9abf3c_0_101),
+ Python Granada ["Python para una IA responsable"](https://docs.google.com/presentation/d/1kil2P6pYuKcan1QcvaxNWXoyoEXkJnBWgpt0gZMfejg/edit?usp=sharing),
+ sobre los Conformal Predictors:
  + [Intro general](https://docs.google.com/presentation/d/1Q6oxcgmNv0GsmNFA5npAzQGDuy_XolBKStN4KUhP4Gk/edit?usp=sharing) (in English).
  + [Key Concepts of Conformal Prediction](https://docs.google.com/presentation/d/1bQYIFyQysQPx79wJq1mltylsH_aeO2AnLYRlHiLq6vo/edit#slide=id.g2dc32e8043a_0_5) (in English).

Como dec√≠amos, √©sta es una serie introductoria y no incluimos explicaciones exhaustivas ni demostraciones matem√°ticas (hay muchas otras fuentes, ver la lista de materiales en la intro de los Jupyter Notebooks), mejor mencionaremos algunas caracter√≠sticas intuitivas sobre la explicabiliad y la cuantificaci√≥n de la incertidumbre y nos enfocaremos en su implementaci√≥n en Scikit-learn (una de las librer√≠as de [Python](https://es.wikipedia.org/wiki/Python) m√°s utilizadas en aprendizaje autom√°tico) y paquetes compatibles.

# Exactitud con certidumbre

En inteligencia artificial, medimos la calidad de las predicciones de un modelo de aprendizaje autom√°tico supervisado a trav√©s de m√©tricas de rendimiento. Por ejemplo, la m√©trica de exactitud (accuracy) en una tarea de clasificaci√≥n cuenta cu√°ntas veces el modelo nos di√≥ la soluci√≥n correcta. El error cuadr√°tico medio (MSE) en una tarea de regresi√≥n mide a qu√© distancia se qued√≥ el modelo de la soluci√≥n correcta. Sin embargo, las m√©tricas de rendimiento no nos ofrecen certeza sobre las predicciones del modelo y esto es un gran problema, sobre todo si es un modelo no interpretable por las personas, tambi√©n llamados modelos de caja opaca (‚Äòblack box models‚Äô).

Un ejemplo es el de un modelo utilizado para clasificar radiograf√≠as de t√≥rax seg√∫n la gravedad de una neumon√≠a. Hab√≠a detectado una marca de la placa cuando la radiograf√≠a se hab√≠a realizado en la planta UCI y ese factor circunstancial era el que primaba en su predicci√≥n  ([_"AI for radiographic COVID-19 detection selects shortcuts over signal"_](https://www.nature.com/articles/s42256-021-00338-7)). Eran un modelo muy exacto, con una m√©trica de exactitud de m√°s del 90% de aciertos, pero en una tarea distinta, no deseada (quer√≠amos detectar una enfermedad, no de d√≥nde ven√≠a la radiograf√≠a). El modelo simplemente encontr√≥ una correlaci√≥n espuria y cogi√≥ el atajo. Y sin poder avisarnos, arroj√≥ predicciones sesgadas.

Como segundo ejemplo imaginemos otro modelo clasificador, esta vez entrenado para predecir si llueve (clase 1) o no llueve (clase 0) dada la temperatura y la humedad del d√≠a. Si cuando lo ponemos en producci√≥n el resultado de un d√≠a es ‚Äú0.8‚Äù, muchos libros, cursos,‚Ä¶ concluyen que eso significa que ‚Äúhay un 80% de probabilidad de que llueva ese d√≠a y un 20% de probabilidad de que no llueva ese d√≠a‚Äù. Sin embargo, esos resultados no est√°n calibrados, es decir, no tienen en cuenta cu√°ntos d√≠as llovi√≥ de verdad, y por tanto no son verdaderas probabilidades. Pero la cosa empeora, ¬øqu√© ocurre si lo que le mostramos al modelo son los datos de un d√≠a con temperatura y humedad muy distintas a las que se usaron en su entrenamiento? Por ejemplo, las de un d√≠a en el planeta Venus. El modelo no tiene manera de decirnos ‚Äúno tengo ni idea de qu√© es esto‚Äù, simplemente arrojar√° un resultado, que en el mejor de los casos estar√° cerca de ‚Äú0.5‚Äù pero no hay ninguna garant√≠a de que as√≠ sea. Y se quedar√° tan pancho, porque no le hemos dado herramientas para mostrar la incertidumbre.

Al automatizar predicciones, si solamente nos fijamos en las m√©tricas de rendimiento, estos problemas pueden pasar f√°cilmente desapercibidos y aumentar el tama√±o del training set no necesariamente los soluciona. Podemos cerciorarnos de que esto no nos pasa incorporando a nuestro modelo ya entrenado ciertas herramientas sencillas para que pueda indicarnos cu√°ndo su predicci√≥n es fiable y cu√°ndo no. Estas herramientas matem√°ticas (ya desarrolladas como librer√≠as de Python y R) explican en qu√© se fij√≥ el modelo para producir sus predicciones (gracias a m√©todos de explicabilidad o ‚ÄúXAI‚Äù, como los SHAP values, LIME,‚Ä¶) o nos proveen de probabilidades calibradas e intervalos de predicci√≥n que incluyen con certeza el valor verdadero para que el modelo pueda avisarnos cuando no debemos confiar en su predicci√≥n (gracias a m√©todos de cuantificaci√≥n de incertidumbre o ‚ÄúUQ‚Äù, como los Conformal Predictors). Y todas son herramientas post-hoc (no hay que volver a entrenar el modelo), model-agnostic (sirven para cualquier modelo y tarea), y muy ligeras (se implementan con pocas l√≠neas de c√≥digo y se ejecutan muy r√°pido).

<font size="10"> üëçü§ì </font>

## Instrucciones
Teniendo Python 3 instalado, hay que seguir estas instrucciones:

0. Clonar el repositorio del taller con el paquete `git`

Para poder descargar los programas, "scripts", o ‚Äúnotebooks‚Äù donde se encuenta el c√≥digo de este taller (tienen extensi√≥n .ipynb porque son Jupyter Notebooks) hay que clonar este repositorio en el ordenador o nube donde vayas a trabajar y para ello necesitamos instalar el paquete de control de versiones `git`, [aqu√≠](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) explica c√≥mo hacerlo si no estuviera ya instalado. Una vez instalado `git`, pincha en el bot√≥n verde con la palabra "Code" que encontrar√°s en esta p√°gina arriba a la derecha, copia al portapapeles la direcci√≥n https, abre una Terminal, navega a la carpeta donde quieras trabajar y p√©ga la direcci√≥n copiada en el portapapeles en la Terminal escribiendo antes `git clone`, un espacio, y despu√©s dichs direcci√≥n https, es decir, hay que escribir y ejecutar:

`git clone https://github.com/MMdeCastro/Uncertainty_Quantification_XAI.git`  

1. Crear entorno con el paquete `venv` 

Siempre es recomendable crear un entorno para evitar incompatibilidad de versiones. Abr√≠ una Terminal nueva y al iniciar estaba en mi carpeta de usuaria en home y he seguido los pasos indicados en la documentaci√≥n de Python https://docs.python.org/es/3/tutorial/venv.html (yo segu√≠ las instrucciones para mi sistema operativo Ubuntu 24.04 con Python 3.12 pero ah√≠ se indican las instrucciones para otros sistemas operativos):

+ Primero instal√© el paquete `venv` escrib√≠ y ejecut√© en la Terminal los comandos:

`sudo apt install python3-venv`

+ Despu√©s con `mkdir` cre√© una carpeta para guardar los entornos, he elegido ocultarla, por eso lleva un punto delante del nombre y he elegido colocarla aqu√≠ mismo donde estoy, en mi home, as√≠ que escrib√≠ y ejecut√©:

`mkdir .venv`

+ Luego cre√© el entorno de `venv` llamado "intro_trustAI_venv" e indiqu√© que lo quer√≠a alojar en la carpeta `.venv`que acababa de crear, as√≠ que  escrib√≠ y ejecut√©:

`python3 -m venv .venv/intro_trustAI_env`

+ Por √∫ltimo, activ√© el entorno escribiendo y ejecutando:

`source .venv/intro_trustAI_venv/bin/activate`

+ Una vez activado el entorno, instal√© el paquete `pip` para instalar el resto de paquetes que vamos a utilizar en el taller, as√≠ que escrib√≠ y ejecut√©:

`sudo apt install python3-pip`

2. Instalar paquetes dentro del entorno
   
+ Con el entorno activo, instal√© los paquetes necesarios para el taller navegando a la carpeta donde clon√© el repositorio de GitHub (ver instrucciones en esta p√°gina m√°s arriba) y escribiendo y ejecutando:

`pip install -r requirements.txt`

3. Abrir y ejecutar el c√≥digo del taller
   
+ Para ver el c√≥digo de los Jupyter Notebooks, escrib√≠ y ejecut√©:

`Jupyter Notebook`

  y se abre un gestor de archivos en el navegador web que tengas por defecto (el m√≠o es Chrome). Se recomienza comenzar por el Jupyter Notebook llamando ‚ÄúExploration_and_Classification.ipnyb‚Äù que explica c√≥mo usar Jupyter Notebooks.

+ Cuando termine, saldr√© del entorno simplemente escribiendo y ejecutando

`deactivate`

Nota: Muchos de los v√≠deos mencionados en los Jupyter Notebooks son de la PyConES22, donde se imparti√≥ este taller por primera vez, y pueden encontrarse en [la lista de reproduci√≥n del canal de youtube de Python Espana](https://www.youtube.com/@PythonES). 
